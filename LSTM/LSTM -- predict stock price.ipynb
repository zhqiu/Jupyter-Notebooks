{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入一些需要用到的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取某股票最近若干天的前复权数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(code,end='2018-01-01', duration=365):\n",
    "    \n",
    "    # 打印股票的基本信息\n",
    "    df = ts.get_stock_basics()\n",
    "    print(df.loc[code][['name', 'industry', 'timeToMarket']])\n",
    "    \n",
    "    d1 = datetime.datetime.strptime(end,'%Y-%m-%d')\n",
    "    d2 = d1 - datetime.timedelta(days=duration)\n",
    "    start = d2.strftime('%Y-%m-%d')\n",
    "\n",
    "    return ts.get_h_data(code, start=start, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个例子 -- 获取数据，保存文件，可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                科大智能\n",
      "industry            电气设备\n",
      "timeToMarket    20110525\n",
      "Name: 300222, dtype: object\n",
      "[Getting data:]############"
     ]
    }
   ],
   "source": [
    "code = '300222'\n",
    "\n",
    "data = get_data(code, duration=365*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('stock_data_730.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stock_data_730.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index([\"date\"], inplace=True)\n",
    "\n",
    "data_sorted = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_sorted.close)\n",
    "plt.title('close prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据集分割为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,SEQ_LENGTH = 25,test_prop=0.137):  # 0.11 for 1095, 0.137 for 730, 0.3 for 365\n",
    "    \n",
    "    ntrain = int(len(data) *(1-test_prop))  # len(data) = 197\n",
    "    predictors = data.columns[:4]  # open, high, close, low\n",
    "    data_pred = data[predictors]\n",
    "    num_attr = data_pred.shape[1]  # 4\n",
    "    \n",
    "    result = np.empty((len(data) - SEQ_LENGTH, SEQ_LENGTH, num_attr))\n",
    "    y = np.empty((len(data) - SEQ_LENGTH, SEQ_LENGTH))\n",
    "    yopen = np.empty((len(data) - SEQ_LENGTH, SEQ_LENGTH))\n",
    "\n",
    "    for index in range(len(data) - SEQ_LENGTH):\n",
    "        result[index, :, :] = data_pred[index: index + SEQ_LENGTH]\n",
    "        y[index, :] = data_pred[index+1: index + SEQ_LENGTH + 1].close\n",
    "        yopen[index, :] = data_pred[index+1: index + SEQ_LENGTH + 1].open\n",
    "\n",
    "    \"\"\"\n",
    "        xtrain的大小：ntrain x SEQ_LENGTH x 4\n",
    "        ytrain的大小：ntrain x SEQ_LENGTH\n",
    "        \n",
    "        * xtrain的每个batch为长为SEQ_LENGTH的连续序列，一共有ntrain个batch，\n",
    "          序列中每个单元都是一个四元组（open，high，close，low）\n",
    "        * ytrain的每个batch为长为SEQ_LENGTH的连续序列，一共有ntrain个batch，\n",
    "          序列中每个单元是xtrain中对应四元组所在日期的下一天的close price\n",
    "        \n",
    "        xtest 的大小：    ntest x SEQ_LENGTH x 4                \n",
    "        ytest的大小：     ntest x SEQ_LENGTH      (close price)\n",
    "        ytest_open的大小：ntest x SEQ_LENGTH      (open price)  \n",
    "        \n",
    "        * xtest的每个batch为长为SEQ_LENGTH的连续序列，一共有ntest个batch，\n",
    "          序列中每个单元都是一个四元组（open，high，close，low）\n",
    "          每一个序列仅包含一个新四元组，且在最后一个\n",
    "        * ytest的每个batch为长为SEQ_LENGTH的连续序列，一共有ntest个batch，\n",
    "          序列中每个单元是xtest中对应四元组所在日期的下一天的close price\n",
    "        \n",
    "        类型：numpy.ndarray\n",
    "    \"\"\"\n",
    "    xtrain = result[:ntrain, :, :]\n",
    "    ytrain = y[:ntrain]\n",
    "    \n",
    "    xtest = result[ntrain:, :, :]\n",
    "    ytest = y[ntrain:]\n",
    "    ytest_open = yopen[ntrain:]\n",
    "    \n",
    "    return xtrain, xtest, ytrain, ytest, ytest_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest, ytest_open = train_test_split(data_sorted)\n",
    "\n",
    "# 转为tensor\n",
    "xtrain = torch.from_numpy(xtrain)\n",
    "ytrain = torch.from_numpy(ytrain)\n",
    "\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ytest = torch.from_numpy(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([372, 25, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([372, 25])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 25, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 25])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取由GAN生成的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = np.load('time_series.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = torch.from_numpy(gen_data).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 26, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data.shape   # 4 attrs: open, high, close, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_xtrain = gen_data[:, :-1, :]\n",
    "gen_ytrain = gen_data[:, 1: , 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 25, 4])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 25])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=30, output_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # 使用两层LSTMCell堆积来提高模型表达力\n",
    "        self.layer1 = nn.LSTMCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "        self.layer2 = nn.LSTMCell(input_size=self.hidden_size, hidden_size=self.hidden_size)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_data, future=0):\n",
    "        outputs = []\n",
    "        \n",
    "        # LSTM cell的三个输入：input(batch,input_size), h_0(batch,hidden_size), c_0(batch,hidden_size)\n",
    "        # batch即为input_data中样本的数量，即为ntrain\n",
    "        # 此处input_data的大小为：ntrain x SEQ_LENGTH X 4\n",
    "        \n",
    "        # init hidden states and cell state for layer1\n",
    "        h_t = torch.zeros(input_data.size(0), self.hidden_size, dtype=torch.double)\n",
    "        c_t = torch.zeros(input_data.size(0), self.hidden_size, dtype=torch.double)\n",
    "        \n",
    "        # init hidden states and cell state for layer2\n",
    "        h_t2 = torch.zeros(input_data.size(0), self.hidden_size, dtype=torch.double)\n",
    "        c_t2 = torch.zeros(input_data.size(0), self.hidden_size, dtype=torch.double)\n",
    "        \n",
    "        # input_data:[ntrain x SEQ_LENGTH X 4]\n",
    "        # chunk将tensor按第二个维度分成 SEQ_LENGTH 块\n",
    "        for i, input_t in enumerate(input_data.chunk(input_data.size(1), dim=1)):\n",
    "            \n",
    "            # reshape: [ntrain x 1 x 4] => [ntrain x 4] \n",
    "            input_t = input_t.squeeze(1)\n",
    "            \n",
    "            # 每个input_t是 ntrain x 4 的tensor， batch=ntrain，input_size=4\n",
    "            h_t, c_t = self.layer1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.layer2(h_t, (h_t2, c_t2))\n",
    "            \n",
    "            # output的大小为 ntrainx1\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "            \n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  0\n",
      "loss: 243.048  gen_loss: 435.437\n",
      "loss: 242.763  gen_loss: 435.033\n",
      "loss: 47.908  gen_loss: 145.131\n",
      "loss: 11.073  gen_loss: 64.107\n",
      "loss: 8.444  gen_loss: 54.968\n",
      "loss: 6.567  gen_loss: 46.646\n",
      "loss: 5.475  gen_loss: 39.342\n",
      "loss: 5.074  gen_loss: 32.996\n",
      "loss: 5.257  gen_loss: 27.763\n",
      "loss: 5.833  gen_loss: 23.581\n",
      "loss: 6.511  gen_loss: 20.697\n",
      "loss: 7.071  gen_loss: 18.919\n",
      "loss: 7.550  gen_loss: 17.638\n",
      "loss: 7.986  gen_loss: 16.604\n",
      "loss: 8.390  gen_loss: 15.726\n",
      "loss: 8.768  gen_loss: 14.957\n",
      "loss: 9.124  gen_loss: 14.270\n",
      "loss: 9.460  gen_loss: 13.643\n",
      "loss: 9.778  gen_loss: 13.057\n",
      "loss: 10.083  gen_loss: 12.493\n",
      "STEP:  1\n",
      "loss: 10.383  gen_loss: 11.922\n",
      "loss: 10.683  gen_loss: 11.296\n",
      "loss: 10.949  gen_loss: 10.547\n",
      "loss: 10.640  gen_loss: 10.082\n",
      "loss: 10.305  gen_loss: 10.124\n",
      "loss: 9.885  gen_loss: 10.236\n",
      "loss: 9.671  gen_loss: 10.285\n",
      "loss: 9.580  gen_loss: 10.232\n",
      "loss: 9.537  gen_loss: 10.055\n",
      "loss: 9.523  gen_loss: 9.785\n",
      "loss: 9.500  gen_loss: 9.488\n",
      "loss: 9.535  gen_loss: 9.099\n",
      "loss: 9.398  gen_loss: 8.814\n",
      "loss: 9.418  gen_loss: 8.440\n",
      "loss: 9.396  gen_loss: 8.081\n",
      "loss: 9.371  gen_loss: 7.592\n",
      "loss: 9.176  gen_loss: 7.087\n",
      "loss: 8.991  gen_loss: 6.260\n",
      "loss: 8.121  gen_loss: 5.849\n",
      "loss: 7.624  gen_loss: 4.853\n",
      "STEP:  2\n",
      "loss: 7.510  gen_loss: 3.960\n",
      "loss: 7.265  gen_loss: 3.537\n",
      "loss: 6.817  gen_loss: 3.027\n",
      "loss: 6.545  gen_loss: 2.081\n",
      "loss: 5.503  gen_loss: 2.092\n",
      "loss: 5.425  gen_loss: 1.890\n",
      "loss: 5.300  gen_loss: 1.837\n",
      "loss: 5.167  gen_loss: 1.729\n",
      "loss: 4.966  gen_loss: 1.633\n",
      "loss: 4.791  gen_loss: 1.504\n",
      "loss: 4.591  gen_loss: 1.409\n",
      "loss: 4.428  gen_loss: 1.313\n",
      "loss: 4.262  gen_loss: 1.243\n",
      "loss: 4.119  gen_loss: 1.174\n",
      "loss: 3.968  gen_loss: 1.129\n",
      "loss: 3.844  gen_loss: 1.082\n",
      "loss: 3.715  gen_loss: 1.060\n",
      "loss: 3.609  gen_loss: 1.032\n",
      "loss: 3.505  gen_loss: 1.024\n",
      "loss: 3.420  gen_loss: 1.012\n",
      "STEP:  3\n",
      "loss: 3.340  gen_loss: 1.012\n",
      "loss: 3.273  gen_loss: 1.009\n",
      "loss: 3.209  gen_loss: 1.012\n",
      "loss: 3.152  gen_loss: 1.014\n",
      "loss: 3.096  gen_loss: 1.019\n",
      "loss: 3.045  gen_loss: 1.023\n",
      "loss: 2.993  gen_loss: 1.029\n",
      "loss: 2.942  gen_loss: 1.035\n",
      "loss: 2.891  gen_loss: 1.042\n",
      "loss: 2.840  gen_loss: 1.049\n",
      "loss: 2.787  gen_loss: 1.057\n",
      "loss: 2.730  gen_loss: 1.065\n",
      "loss: 2.670  gen_loss: 1.068\n",
      "loss: 2.593  gen_loss: 1.073\n",
      "loss: 2.505  gen_loss: 1.069\n",
      "loss: 2.351  gen_loss: 1.054\n",
      "loss: 2.143  gen_loss: 1.033\n",
      "loss: 2.042  gen_loss: 1.044\n",
      "loss: 1.982  gen_loss: 1.056\n",
      "loss: 1.941  gen_loss: 1.053\n",
      "STEP:  4\n",
      "loss: 1.902  gen_loss: 1.060\n",
      "loss: 1.874  gen_loss: 1.059\n",
      "loss: 1.846  gen_loss: 1.061\n",
      "loss: 1.820  gen_loss: 1.060\n",
      "loss: 1.790  gen_loss: 1.061\n",
      "loss: 1.756  gen_loss: 1.059\n",
      "loss: 1.715  gen_loss: 1.059\n",
      "loss: 1.667  gen_loss: 1.056\n",
      "loss: 1.606  gen_loss: 1.057\n",
      "loss: 1.527  gen_loss: 1.056\n",
      "loss: 1.428  gen_loss: 1.063\n",
      "loss: 1.337  gen_loss: 1.079\n",
      "loss: 1.309  gen_loss: 1.083\n",
      "loss: 1.297  gen_loss: 1.079\n",
      "loss: 1.285  gen_loss: 1.077\n",
      "loss: 1.272  gen_loss: 1.075\n",
      "loss: 1.257  gen_loss: 1.074\n",
      "loss: 1.242  gen_loss: 1.072\n",
      "loss: 1.222  gen_loss: 1.075\n",
      "loss: 1.201  gen_loss: 1.067\n",
      "STEP:  5\n",
      "loss: 1.158  gen_loss: 1.078\n",
      "loss: 1.127  gen_loss: 1.082\n",
      "loss: 1.099  gen_loss: 1.087\n",
      "loss: 1.070  gen_loss: 1.092\n",
      "loss: 1.041  gen_loss: 1.098\n",
      "loss: 1.013  gen_loss: 1.103\n",
      "loss: 0.984  gen_loss: 1.110\n",
      "loss: 0.957  gen_loss: 1.114\n",
      "loss: 0.928  gen_loss: 1.122\n",
      "loss: 0.904  gen_loss: 1.127\n",
      "loss: 0.880  gen_loss: 1.134\n",
      "loss: 0.859  gen_loss: 1.138\n",
      "loss: 0.839  gen_loss: 1.143\n",
      "loss: 0.819  gen_loss: 1.148\n",
      "loss: 0.800  gen_loss: 1.153\n",
      "loss: 0.782  gen_loss: 1.157\n",
      "loss: 0.765  gen_loss: 1.161\n",
      "loss: 0.750  gen_loss: 1.164\n",
      "loss: 0.735  gen_loss: 1.167\n",
      "loss: 0.722  gen_loss: 1.170\n",
      "STEP:  6\n",
      "loss: 0.709  gen_loss: 1.173\n",
      "loss: 0.696  gen_loss: 1.175\n",
      "loss: 0.685  gen_loss: 1.176\n",
      "loss: 0.674  gen_loss: 1.178\n",
      "loss: 0.662  gen_loss: 1.178\n",
      "loss: 0.649  gen_loss: 1.178\n",
      "loss: 0.637  gen_loss: 1.177\n",
      "loss: 0.626  gen_loss: 1.175\n",
      "loss: 0.615  gen_loss: 1.173\n",
      "loss: 0.605  gen_loss: 1.171\n",
      "loss: 0.595  gen_loss: 1.169\n",
      "loss: 0.587  gen_loss: 1.166\n",
      "loss: 0.579  gen_loss: 1.163\n",
      "loss: 0.571  gen_loss: 1.160\n",
      "loss: 0.564  gen_loss: 1.156\n",
      "loss: 0.558  gen_loss: 1.153\n",
      "loss: 0.551  gen_loss: 1.149\n",
      "loss: 0.546  gen_loss: 1.146\n",
      "loss: 0.540  gen_loss: 1.142\n",
      "loss: 0.534  gen_loss: 1.138\n",
      "STEP:  7\n",
      "loss: 0.529  gen_loss: 1.134\n",
      "loss: 0.524  gen_loss: 1.129\n",
      "loss: 0.519  gen_loss: 1.125\n",
      "loss: 0.514  gen_loss: 1.120\n",
      "loss: 0.509  gen_loss: 1.114\n",
      "loss: 0.506  gen_loss: 1.107\n",
      "loss: 0.502  gen_loss: 1.101\n",
      "loss: 0.499  gen_loss: 1.093\n",
      "loss: 0.496  gen_loss: 1.086\n",
      "loss: 0.495  gen_loss: 1.078\n",
      "loss: 0.493  gen_loss: 1.071\n",
      "loss: 0.493  gen_loss: 1.063\n",
      "loss: 0.493  gen_loss: 1.055\n",
      "loss: 0.494  gen_loss: 1.047\n",
      "loss: 0.495  gen_loss: 1.039\n",
      "loss: 0.497  gen_loss: 1.029\n",
      "loss: 0.498  gen_loss: 1.020\n",
      "loss: 0.500  gen_loss: 1.010\n",
      "loss: 0.502  gen_loss: 1.000\n",
      "loss: 0.504  gen_loss: 0.989\n",
      "STEP:  8\n",
      "loss: 0.508  gen_loss: 0.976\n",
      "loss: 0.510  gen_loss: 0.969\n",
      "loss: 0.509  gen_loss: 0.961\n",
      "loss: 0.510  gen_loss: 0.953\n",
      "loss: 0.510  gen_loss: 0.941\n",
      "loss: 0.509  gen_loss: 0.932\n",
      "loss: 0.507  gen_loss: 0.920\n",
      "loss: 0.504  gen_loss: 0.909\n",
      "loss: 0.498  gen_loss: 0.896\n",
      "loss: 0.493  gen_loss: 0.886\n",
      "loss: 0.486  gen_loss: 0.877\n",
      "loss: 0.482  gen_loss: 0.872\n",
      "loss: 0.478  gen_loss: 0.867\n",
      "loss: 0.474  gen_loss: 0.865\n",
      "loss: 0.471  gen_loss: 0.862\n",
      "loss: 0.468  gen_loss: 0.860\n",
      "loss: 0.466  gen_loss: 0.859\n",
      "loss: 0.464  gen_loss: 0.858\n",
      "loss: 0.463  gen_loss: 0.857\n",
      "loss: 0.461  gen_loss: 0.856\n",
      "STEP:  9\n",
      "loss: 0.460  gen_loss: 0.855\n",
      "loss: 0.458  gen_loss: 0.855\n",
      "loss: 0.457  gen_loss: 0.854\n",
      "loss: 0.455  gen_loss: 0.854\n",
      "loss: 0.453  gen_loss: 0.854\n",
      "loss: 0.451  gen_loss: 0.854\n",
      "loss: 0.448  gen_loss: 0.854\n",
      "loss: 0.445  gen_loss: 0.855\n",
      "loss: 0.442  gen_loss: 0.856\n",
      "loss: 0.438  gen_loss: 0.857\n",
      "loss: 0.433  gen_loss: 0.858\n",
      "loss: 0.428  gen_loss: 0.859\n",
      "loss: 0.422  gen_loss: 0.861\n",
      "loss: 0.416  gen_loss: 0.863\n",
      "loss: 0.410  gen_loss: 0.864\n",
      "loss: 0.406  gen_loss: 0.864\n",
      "loss: 0.402  gen_loss: 0.865\n",
      "loss: 0.398  gen_loss: 0.865\n",
      "loss: 0.395  gen_loss: 0.866\n",
      "loss: 0.392  gen_loss: 0.866\n",
      "STEP:  10\n",
      "loss: 0.390  gen_loss: 0.866\n",
      "loss: 0.388  gen_loss: 0.865\n",
      "loss: 0.386  gen_loss: 0.865\n",
      "loss: 0.384  gen_loss: 0.865\n",
      "loss: 0.382  gen_loss: 0.864\n",
      "loss: 0.381  gen_loss: 0.864\n",
      "loss: 0.379  gen_loss: 0.863\n",
      "loss: 0.377  gen_loss: 0.862\n",
      "loss: 0.376  gen_loss: 0.861\n",
      "loss: 0.374  gen_loss: 0.860\n",
      "loss: 0.373  gen_loss: 0.859\n",
      "loss: 0.372  gen_loss: 0.858\n",
      "loss: 0.371  gen_loss: 0.857\n",
      "loss: 0.371  gen_loss: 0.855\n",
      "loss: 0.370  gen_loss: 0.854\n",
      "loss: 0.369  gen_loss: 0.853\n",
      "loss: 0.368  gen_loss: 0.852\n",
      "loss: 0.367  gen_loss: 0.851\n",
      "loss: 0.366  gen_loss: 0.850\n",
      "loss: 0.365  gen_loss: 0.850\n",
      "STEP:  11\n",
      "loss: 0.365  gen_loss: 0.849\n",
      "loss: 0.364  gen_loss: 0.848\n",
      "loss: 0.363  gen_loss: 0.847\n",
      "loss: 0.362  gen_loss: 0.846\n",
      "loss: 0.361  gen_loss: 0.845\n",
      "loss: 0.360  gen_loss: 0.842\n",
      "loss: 0.360  gen_loss: 0.840\n",
      "loss: 0.359  gen_loss: 0.837\n",
      "loss: 0.359  gen_loss: 0.834\n",
      "loss: 0.359  gen_loss: 0.832\n",
      "loss: 0.360  gen_loss: 0.829\n",
      "loss: 0.360  gen_loss: 0.826\n",
      "loss: 0.359  gen_loss: 0.823\n",
      "loss: 0.359  gen_loss: 0.820\n",
      "loss: 0.359  gen_loss: 0.818\n",
      "loss: 0.359  gen_loss: 0.815\n",
      "loss: 0.359  gen_loss: 0.812\n",
      "loss: 0.358  gen_loss: 0.810\n",
      "loss: 0.358  gen_loss: 0.808\n",
      "loss: 0.357  gen_loss: 0.806\n",
      "STEP:  12\n",
      "loss: 0.356  gen_loss: 0.804\n",
      "loss: 0.356  gen_loss: 0.802\n",
      "loss: 0.355  gen_loss: 0.801\n",
      "loss: 0.354  gen_loss: 0.799\n",
      "loss: 0.353  gen_loss: 0.798\n",
      "loss: 0.353  gen_loss: 0.797\n",
      "loss: 0.352  gen_loss: 0.796\n",
      "loss: 0.351  gen_loss: 0.795\n",
      "loss: 0.351  gen_loss: 0.795\n",
      "loss: 0.350  gen_loss: 0.794\n",
      "loss: 0.350  gen_loss: 0.794\n",
      "loss: 0.349  gen_loss: 0.793\n",
      "loss: 0.349  gen_loss: 0.793\n",
      "loss: 0.348  gen_loss: 0.792\n",
      "loss: 0.348  gen_loss: 0.792\n",
      "loss: 0.348  gen_loss: 0.792\n",
      "loss: 0.347  gen_loss: 0.791\n",
      "loss: 0.347  gen_loss: 0.791\n",
      "loss: 0.347  gen_loss: 0.790\n",
      "loss: 0.347  gen_loss: 0.790\n",
      "STEP:  13\n",
      "loss: 0.346  gen_loss: 0.790\n",
      "loss: 0.346  gen_loss: 0.789\n",
      "loss: 0.345  gen_loss: 0.789\n",
      "loss: 0.344  gen_loss: 0.789\n",
      "loss: 0.344  gen_loss: 0.788\n",
      "loss: 0.345  gen_loss: 0.787\n",
      "loss: 0.345  gen_loss: 0.786\n",
      "loss: 0.345  gen_loss: 0.784\n",
      "loss: 0.345  gen_loss: 0.783\n",
      "loss: 0.345  gen_loss: 0.781\n",
      "loss: 0.345  gen_loss: 0.780\n",
      "loss: 0.345  gen_loss: 0.778\n",
      "loss: 0.345  gen_loss: 0.776\n",
      "loss: 0.346  gen_loss: 0.773\n",
      "loss: 0.346  gen_loss: 0.772\n",
      "loss: 0.347  gen_loss: 0.769\n",
      "loss: 0.347  gen_loss: 0.768\n",
      "loss: 0.347  gen_loss: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.347  gen_loss: 0.765\n",
      "loss: 0.347  gen_loss: 0.764\n",
      "STEP:  14\n",
      "loss: 0.347  gen_loss: 0.763\n",
      "loss: 0.347  gen_loss: 0.761\n",
      "loss: 0.347  gen_loss: 0.760\n",
      "loss: 0.347  gen_loss: 0.759\n",
      "loss: 0.347  gen_loss: 0.758\n",
      "loss: 0.347  gen_loss: 0.757\n",
      "loss: 0.347  gen_loss: 0.756\n",
      "loss: 0.347  gen_loss: 0.755\n",
      "loss: 0.347  gen_loss: 0.755\n",
      "loss: 0.347  gen_loss: 0.754\n",
      "loss: 0.347  gen_loss: 0.753\n",
      "loss: 0.347  gen_loss: 0.752\n",
      "loss: 0.346  gen_loss: 0.752\n",
      "loss: 0.347  gen_loss: 0.751\n",
      "loss: 0.347  gen_loss: 0.750\n",
      "loss: 0.347  gen_loss: 0.749\n",
      "loss: 0.347  gen_loss: 0.749\n",
      "loss: 0.347  gen_loss: 0.748\n",
      "loss: 0.347  gen_loss: 0.747\n",
      "loss: 0.347  gen_loss: 0.747\n",
      "STEP:  15\n",
      "loss: 0.347  gen_loss: 0.746\n",
      "loss: 0.347  gen_loss: 0.745\n",
      "loss: 0.347  gen_loss: 0.745\n",
      "loss: 0.347  gen_loss: 0.744\n",
      "loss: 0.347  gen_loss: 0.744\n",
      "loss: 0.347  gen_loss: 0.744\n",
      "loss: 0.347  gen_loss: 0.743\n",
      "loss: 0.346  gen_loss: 0.743\n",
      "loss: 0.346  gen_loss: 0.743\n",
      "loss: 0.345  gen_loss: 0.743\n",
      "loss: 0.345  gen_loss: 0.742\n",
      "loss: 0.344  gen_loss: 0.742\n",
      "loss: 0.344  gen_loss: 0.742\n",
      "loss: 0.343  gen_loss: 0.743\n",
      "loss: 0.342  gen_loss: 0.743\n",
      "loss: 0.341  gen_loss: 0.743\n",
      "loss: 0.340  gen_loss: 0.744\n",
      "loss: 0.339  gen_loss: 0.744\n",
      "loss: 0.338  gen_loss: 0.744\n",
      "loss: 0.337  gen_loss: 0.745\n",
      "STEP:  16\n",
      "loss: 0.337  gen_loss: 0.745\n",
      "loss: 0.336  gen_loss: 0.746\n",
      "loss: 0.335  gen_loss: 0.746\n",
      "loss: 0.335  gen_loss: 0.746\n",
      "loss: 0.334  gen_loss: 0.747\n",
      "loss: 0.333  gen_loss: 0.747\n",
      "loss: 0.333  gen_loss: 0.748\n",
      "loss: 0.332  gen_loss: 0.748\n",
      "loss: 0.332  gen_loss: 0.748\n",
      "loss: 0.332  gen_loss: 0.749\n",
      "loss: 0.331  gen_loss: 0.749\n",
      "loss: 0.331  gen_loss: 0.749\n",
      "loss: 0.330  gen_loss: 0.749\n",
      "loss: 0.330  gen_loss: 0.750\n",
      "loss: 0.330  gen_loss: 0.750\n",
      "loss: 0.329  gen_loss: 0.750\n",
      "loss: 0.329  gen_loss: 0.751\n",
      "loss: 0.328  gen_loss: 0.751\n",
      "loss: 0.328  gen_loss: 0.751\n",
      "loss: 0.328  gen_loss: 0.751\n",
      "STEP:  17\n",
      "loss: 0.327  gen_loss: 0.752\n",
      "loss: 0.327  gen_loss: 0.752\n",
      "loss: 0.326  gen_loss: 0.752\n",
      "loss: 0.326  gen_loss: 0.753\n",
      "loss: 0.325  gen_loss: 0.753\n",
      "loss: 0.325  gen_loss: 0.753\n",
      "loss: 0.324  gen_loss: 0.753\n",
      "loss: 0.323  gen_loss: 0.753\n",
      "loss: 0.323  gen_loss: 0.754\n",
      "loss: 0.322  gen_loss: 0.754\n",
      "loss: 0.322  gen_loss: 0.754\n",
      "loss: 0.321  gen_loss: 0.754\n",
      "loss: 0.321  gen_loss: 0.754\n",
      "loss: 0.320  gen_loss: 0.753\n",
      "loss: 0.320  gen_loss: 0.753\n",
      "loss: 0.320  gen_loss: 0.753\n",
      "loss: 0.319  gen_loss: 0.752\n",
      "loss: 0.319  gen_loss: 0.751\n",
      "loss: 0.319  gen_loss: 0.751\n",
      "loss: 0.319  gen_loss: 0.750\n",
      "STEP:  18\n",
      "loss: 0.319  gen_loss: 0.749\n",
      "loss: 0.319  gen_loss: 0.748\n",
      "loss: 0.319  gen_loss: 0.747\n",
      "loss: 0.319  gen_loss: 0.746\n",
      "loss: 0.319  gen_loss: 0.745\n",
      "loss: 0.320  gen_loss: 0.743\n",
      "loss: 0.320  gen_loss: 0.742\n",
      "loss: 0.320  gen_loss: 0.741\n",
      "loss: 0.321  gen_loss: 0.740\n",
      "loss: 0.321  gen_loss: 0.739\n",
      "loss: 0.321  gen_loss: 0.738\n",
      "loss: 0.322  gen_loss: 0.737\n",
      "loss: 0.322  gen_loss: 0.736\n",
      "loss: 0.322  gen_loss: 0.735\n",
      "loss: 0.323  gen_loss: 0.734\n",
      "loss: 0.323  gen_loss: 0.733\n",
      "loss: 0.324  gen_loss: 0.731\n",
      "loss: 0.324  gen_loss: 0.730\n",
      "loss: 0.325  gen_loss: 0.729\n",
      "loss: 0.325  gen_loss: 0.728\n",
      "STEP:  19\n",
      "loss: 0.326  gen_loss: 0.727\n",
      "loss: 0.326  gen_loss: 0.726\n",
      "loss: 0.327  gen_loss: 0.725\n",
      "loss: 0.328  gen_loss: 0.723\n",
      "loss: 0.328  gen_loss: 0.721\n",
      "loss: 0.329  gen_loss: 0.719\n",
      "loss: 0.330  gen_loss: 0.717\n",
      "loss: 0.331  gen_loss: 0.715\n",
      "loss: 0.332  gen_loss: 0.713\n",
      "loss: 0.333  gen_loss: 0.711\n",
      "loss: 0.334  gen_loss: 0.709\n",
      "loss: 0.335  gen_loss: 0.707\n",
      "loss: 0.336  gen_loss: 0.705\n",
      "loss: 0.336  gen_loss: 0.704\n",
      "loss: 0.337  gen_loss: 0.702\n",
      "loss: 0.337  gen_loss: 0.701\n",
      "loss: 0.338  gen_loss: 0.700\n",
      "loss: 0.338  gen_loss: 0.698\n",
      "loss: 0.339  gen_loss: 0.697\n",
      "loss: 0.339  gen_loss: 0.696\n",
      "STEP:  20\n",
      "loss: 0.339  gen_loss: 0.695\n",
      "loss: 0.340  gen_loss: 0.694\n",
      "loss: 0.340  gen_loss: 0.693\n",
      "loss: 0.340  gen_loss: 0.692\n",
      "loss: 0.340  gen_loss: 0.692\n",
      "loss: 0.340  gen_loss: 0.691\n",
      "loss: 0.340  gen_loss: 0.691\n",
      "loss: 0.340  gen_loss: 0.690\n",
      "loss: 0.340  gen_loss: 0.690\n",
      "loss: 0.340  gen_loss: 0.689\n",
      "loss: 0.340  gen_loss: 0.689\n",
      "loss: 0.340  gen_loss: 0.688\n",
      "loss: 0.340  gen_loss: 0.688\n",
      "loss: 0.340  gen_loss: 0.688\n",
      "loss: 0.339  gen_loss: 0.688\n",
      "loss: 0.339  gen_loss: 0.687\n",
      "loss: 0.339  gen_loss: 0.687\n",
      "loss: 0.338  gen_loss: 0.687\n",
      "loss: 0.337  gen_loss: 0.687\n",
      "loss: 0.336  gen_loss: 0.687\n",
      "STEP:  21\n",
      "loss: 0.335  gen_loss: 0.687\n",
      "loss: 0.335  gen_loss: 0.687\n",
      "loss: 0.334  gen_loss: 0.687\n",
      "loss: 0.333  gen_loss: 0.686\n",
      "loss: 0.332  gen_loss: 0.686\n",
      "loss: 0.331  gen_loss: 0.686\n",
      "loss: 0.330  gen_loss: 0.685\n",
      "loss: 0.329  gen_loss: 0.685\n",
      "loss: 0.328  gen_loss: 0.684\n",
      "loss: 0.328  gen_loss: 0.683\n",
      "loss: 0.327  gen_loss: 0.683\n",
      "loss: 0.327  gen_loss: 0.682\n",
      "loss: 0.327  gen_loss: 0.682\n",
      "loss: 0.327  gen_loss: 0.681\n",
      "loss: 0.327  gen_loss: 0.680\n",
      "loss: 0.328  gen_loss: 0.679\n",
      "loss: 0.328  gen_loss: 0.678\n",
      "loss: 0.329  gen_loss: 0.676\n",
      "loss: 0.330  gen_loss: 0.674\n",
      "loss: 0.330  gen_loss: 0.672\n",
      "STEP:  22\n",
      "loss: 0.331  gen_loss: 0.669\n",
      "loss: 0.332  gen_loss: 0.668\n",
      "loss: 0.333  gen_loss: 0.666\n",
      "loss: 0.334  gen_loss: 0.664\n",
      "loss: 0.334  gen_loss: 0.662\n",
      "loss: 0.335  gen_loss: 0.660\n",
      "loss: 0.336  gen_loss: 0.659\n",
      "loss: 0.336  gen_loss: 0.657\n",
      "loss: 0.336  gen_loss: 0.656\n",
      "loss: 0.337  gen_loss: 0.655\n",
      "loss: 0.337  gen_loss: 0.654\n",
      "loss: 0.337  gen_loss: 0.653\n",
      "loss: 0.337  gen_loss: 0.652\n",
      "loss: 0.337  gen_loss: 0.651\n",
      "loss: 0.337  gen_loss: 0.650\n",
      "loss: 0.337  gen_loss: 0.650\n",
      "loss: 0.337  gen_loss: 0.649\n",
      "loss: 0.337  gen_loss: 0.648\n",
      "loss: 0.337  gen_loss: 0.647\n",
      "loss: 0.337  gen_loss: 0.646\n",
      "STEP:  23\n",
      "loss: 0.337  gen_loss: 0.645\n",
      "loss: 0.337  gen_loss: 0.645\n",
      "loss: 0.337  gen_loss: 0.644\n",
      "loss: 0.337  gen_loss: 0.643\n",
      "loss: 0.337  gen_loss: 0.643\n",
      "loss: 0.337  gen_loss: 0.642\n",
      "loss: 0.337  gen_loss: 0.641\n",
      "loss: 0.337  gen_loss: 0.641\n",
      "loss: 0.337  gen_loss: 0.640\n",
      "loss: 0.337  gen_loss: 0.639\n",
      "loss: 0.338  gen_loss: 0.638\n",
      "loss: 0.338  gen_loss: 0.637\n",
      "loss: 0.338  gen_loss: 0.636\n",
      "loss: 0.339  gen_loss: 0.635\n",
      "loss: 0.339  gen_loss: 0.634\n",
      "loss: 0.339  gen_loss: 0.633\n",
      "loss: 0.339  gen_loss: 0.633\n",
      "loss: 0.340  gen_loss: 0.632\n",
      "loss: 0.340  gen_loss: 0.630\n",
      "loss: 0.340  gen_loss: 0.629\n",
      "STEP:  24\n",
      "loss: 0.341  gen_loss: 0.628\n",
      "loss: 0.341  gen_loss: 0.628\n",
      "loss: 0.341  gen_loss: 0.626\n",
      "loss: 0.342  gen_loss: 0.626\n",
      "loss: 0.342  gen_loss: 0.625\n",
      "loss: 0.342  gen_loss: 0.624\n",
      "loss: 0.342  gen_loss: 0.623\n",
      "loss: 0.342  gen_loss: 0.622\n",
      "loss: 0.343  gen_loss: 0.621\n",
      "loss: 0.343  gen_loss: 0.621\n",
      "loss: 0.343  gen_loss: 0.620\n",
      "loss: 0.343  gen_loss: 0.619\n",
      "loss: 0.343  gen_loss: 0.618\n",
      "loss: 0.343  gen_loss: 0.618\n",
      "loss: 0.343  gen_loss: 0.617\n",
      "loss: 0.343  gen_loss: 0.617\n",
      "loss: 0.344  gen_loss: 0.616\n",
      "loss: 0.344  gen_loss: 0.615\n",
      "loss: 0.344  gen_loss: 0.614\n",
      "loss: 0.344  gen_loss: 0.614\n",
      "STEP:  25\n",
      "loss: 0.345  gen_loss: 0.613\n",
      "loss: 0.345  gen_loss: 0.612\n",
      "loss: 0.345  gen_loss: 0.612\n",
      "loss: 0.345  gen_loss: 0.611\n",
      "loss: 0.345  gen_loss: 0.610\n",
      "loss: 0.345  gen_loss: 0.610\n",
      "loss: 0.346  gen_loss: 0.609\n",
      "loss: 0.346  gen_loss: 0.608\n",
      "loss: 0.346  gen_loss: 0.608\n",
      "loss: 0.346  gen_loss: 0.607\n",
      "loss: 0.346  gen_loss: 0.607\n",
      "loss: 0.346  gen_loss: 0.606\n",
      "loss: 0.346  gen_loss: 0.606\n",
      "loss: 0.347  gen_loss: 0.605\n",
      "loss: 0.347  gen_loss: 0.605\n",
      "loss: 0.347  gen_loss: 0.604\n",
      "loss: 0.347  gen_loss: 0.604\n",
      "loss: 0.347  gen_loss: 0.603\n",
      "loss: 0.347  gen_loss: 0.603\n",
      "loss: 0.347  gen_loss: 0.602\n",
      "STEP:  26\n",
      "loss: 0.347  gen_loss: 0.602\n",
      "loss: 0.347  gen_loss: 0.602\n",
      "loss: 0.347  gen_loss: 0.601\n",
      "loss: 0.347  gen_loss: 0.601\n",
      "loss: 0.346  gen_loss: 0.601\n",
      "loss: 0.346  gen_loss: 0.600\n",
      "loss: 0.346  gen_loss: 0.600\n",
      "loss: 0.346  gen_loss: 0.600\n",
      "loss: 0.345  gen_loss: 0.600\n",
      "loss: 0.345  gen_loss: 0.600\n",
      "loss: 0.345  gen_loss: 0.599\n",
      "loss: 0.344  gen_loss: 0.600\n",
      "loss: 0.343  gen_loss: 0.600\n",
      "loss: 0.343  gen_loss: 0.600\n",
      "loss: 0.342  gen_loss: 0.599\n",
      "loss: 0.342  gen_loss: 0.599\n",
      "loss: 0.341  gen_loss: 0.600\n",
      "loss: 0.340  gen_loss: 0.600\n",
      "loss: 0.339  gen_loss: 0.600\n",
      "loss: 0.339  gen_loss: 0.600\n",
      "STEP:  27\n",
      "loss: 0.338  gen_loss: 0.600\n",
      "loss: 0.337  gen_loss: 0.601\n",
      "loss: 0.337  gen_loss: 0.601\n",
      "loss: 0.336  gen_loss: 0.601\n",
      "loss: 0.335  gen_loss: 0.601\n",
      "loss: 0.335  gen_loss: 0.602\n",
      "loss: 0.334  gen_loss: 0.602\n",
      "loss: 0.333  gen_loss: 0.602\n",
      "loss: 0.333  gen_loss: 0.602\n",
      "loss: 0.332  gen_loss: 0.601\n",
      "loss: 0.331  gen_loss: 0.601\n",
      "loss: 0.330  gen_loss: 0.601\n",
      "loss: 0.330  gen_loss: 0.600\n",
      "loss: 0.329  gen_loss: 0.599\n",
      "loss: 0.329  gen_loss: 0.597\n",
      "loss: 0.328  gen_loss: 0.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.328  gen_loss: 0.594\n",
      "loss: 0.328  gen_loss: 0.592\n",
      "loss: 0.328  gen_loss: 0.590\n",
      "loss: 0.329  gen_loss: 0.589\n",
      "STEP:  28\n",
      "loss: 0.329  gen_loss: 0.586\n",
      "loss: 0.329  gen_loss: 0.584\n",
      "loss: 0.329  gen_loss: 0.582\n",
      "loss: 0.330  gen_loss: 0.580\n",
      "loss: 0.330  gen_loss: 0.578\n",
      "loss: 0.330  gen_loss: 0.575\n",
      "loss: 0.331  gen_loss: 0.574\n",
      "loss: 0.331  gen_loss: 0.572\n",
      "loss: 0.331  gen_loss: 0.570\n",
      "loss: 0.331  gen_loss: 0.569\n",
      "loss: 0.331  gen_loss: 0.568\n",
      "loss: 0.332  gen_loss: 0.566\n",
      "loss: 0.332  gen_loss: 0.565\n",
      "loss: 0.332  gen_loss: 0.564\n",
      "loss: 0.332  gen_loss: 0.563\n",
      "loss: 0.332  gen_loss: 0.561\n",
      "loss: 0.332  gen_loss: 0.560\n",
      "loss: 0.332  gen_loss: 0.559\n",
      "loss: 0.332  gen_loss: 0.558\n",
      "loss: 0.333  gen_loss: 0.557\n",
      "STEP:  29\n",
      "loss: 0.333  gen_loss: 0.555\n",
      "loss: 0.333  gen_loss: 0.554\n",
      "loss: 0.333  gen_loss: 0.552\n",
      "loss: 0.334  gen_loss: 0.551\n",
      "loss: 0.334  gen_loss: 0.549\n",
      "loss: 0.335  gen_loss: 0.548\n",
      "loss: 0.335  gen_loss: 0.546\n",
      "loss: 0.335  gen_loss: 0.544\n",
      "loss: 0.336  gen_loss: 0.542\n",
      "loss: 0.336  gen_loss: 0.540\n",
      "loss: 0.337  gen_loss: 0.538\n",
      "loss: 0.337  gen_loss: 0.536\n",
      "loss: 0.338  gen_loss: 0.533\n",
      "loss: 0.338  gen_loss: 0.531\n",
      "loss: 0.339  gen_loss: 0.529\n",
      "loss: 0.339  gen_loss: 0.527\n",
      "loss: 0.339  gen_loss: 0.525\n",
      "loss: 0.340  gen_loss: 0.523\n",
      "loss: 0.340  gen_loss: 0.521\n",
      "loss: 0.340  gen_loss: 0.520\n",
      "STEP:  30\n",
      "loss: 0.341  gen_loss: 0.518\n",
      "loss: 0.341  gen_loss: 0.517\n",
      "loss: 0.341  gen_loss: 0.515\n",
      "loss: 0.342  gen_loss: 0.514\n",
      "loss: 0.342  gen_loss: 0.513\n",
      "loss: 0.342  gen_loss: 0.511\n",
      "loss: 0.343  gen_loss: 0.510\n",
      "loss: 0.343  gen_loss: 0.509\n",
      "loss: 0.343  gen_loss: 0.508\n",
      "loss: 0.344  gen_loss: 0.507\n",
      "loss: 0.344  gen_loss: 0.506\n",
      "loss: 0.344  gen_loss: 0.504\n",
      "loss: 0.345  gen_loss: 0.503\n",
      "loss: 0.345  gen_loss: 0.502\n",
      "loss: 0.345  gen_loss: 0.501\n",
      "loss: 0.346  gen_loss: 0.500\n",
      "loss: 0.346  gen_loss: 0.499\n",
      "loss: 0.347  gen_loss: 0.497\n",
      "loss: 0.347  gen_loss: 0.496\n",
      "loss: 0.348  gen_loss: 0.495\n",
      "STEP:  31\n",
      "loss: 0.348  gen_loss: 0.494\n",
      "loss: 0.348  gen_loss: 0.492\n",
      "loss: 0.349  gen_loss: 0.491\n",
      "loss: 0.349  gen_loss: 0.490\n",
      "loss: 0.350  gen_loss: 0.489\n",
      "loss: 0.350  gen_loss: 0.488\n",
      "loss: 0.350  gen_loss: 0.487\n",
      "loss: 0.351  gen_loss: 0.485\n",
      "loss: 0.351  gen_loss: 0.484\n",
      "loss: 0.352  gen_loss: 0.483\n",
      "loss: 0.352  gen_loss: 0.482\n",
      "loss: 0.353  gen_loss: 0.480\n",
      "loss: 0.353  gen_loss: 0.479\n",
      "loss: 0.354  gen_loss: 0.478\n",
      "loss: 0.354  gen_loss: 0.477\n",
      "loss: 0.355  gen_loss: 0.476\n",
      "loss: 0.355  gen_loss: 0.475\n",
      "loss: 0.356  gen_loss: 0.473\n",
      "loss: 0.356  gen_loss: 0.472\n",
      "loss: 0.357  gen_loss: 0.471\n",
      "STEP:  32\n",
      "loss: 0.357  gen_loss: 0.470\n",
      "loss: 0.358  gen_loss: 0.468\n",
      "loss: 0.359  gen_loss: 0.467\n",
      "loss: 0.359  gen_loss: 0.466\n",
      "loss: 0.360  gen_loss: 0.465\n",
      "loss: 0.360  gen_loss: 0.464\n",
      "loss: 0.361  gen_loss: 0.463\n",
      "loss: 0.361  gen_loss: 0.462\n",
      "loss: 0.362  gen_loss: 0.461\n",
      "loss: 0.362  gen_loss: 0.460\n",
      "loss: 0.365  gen_loss: 0.457\n",
      "loss: 0.365  gen_loss: 0.457\n",
      "loss: 0.366  gen_loss: 0.456\n",
      "loss: 0.366  gen_loss: 0.455\n",
      "loss: 0.366  gen_loss: 0.454\n",
      "loss: 0.366  gen_loss: 0.453\n",
      "loss: 0.366  gen_loss: 0.453\n",
      "loss: 0.366  gen_loss: 0.452\n",
      "loss: 0.366  gen_loss: 0.451\n",
      "loss: 0.366  gen_loss: 0.451\n",
      "STEP:  33\n",
      "loss: 0.366  gen_loss: 0.450\n",
      "loss: 0.366  gen_loss: 0.449\n",
      "loss: 0.366  gen_loss: 0.449\n",
      "loss: 0.366  gen_loss: 0.449\n",
      "loss: 0.365  gen_loss: 0.448\n",
      "loss: 0.365  gen_loss: 0.448\n",
      "loss: 0.364  gen_loss: 0.448\n",
      "loss: 0.364  gen_loss: 0.448\n",
      "loss: 0.363  gen_loss: 0.448\n",
      "loss: 0.363  gen_loss: 0.448\n",
      "loss: 0.362  gen_loss: 0.448\n",
      "loss: 0.361  gen_loss: 0.448\n",
      "loss: 0.361  gen_loss: 0.448\n",
      "loss: 0.360  gen_loss: 0.449\n",
      "loss: 0.359  gen_loss: 0.449\n",
      "loss: 0.359  gen_loss: 0.449\n",
      "loss: 0.358  gen_loss: 0.449\n",
      "loss: 0.357  gen_loss: 0.449\n",
      "loss: 0.356  gen_loss: 0.450\n",
      "loss: 0.355  gen_loss: 0.450\n",
      "STEP:  34\n",
      "loss: 0.355  gen_loss: 0.450\n",
      "loss: 0.354  gen_loss: 0.451\n",
      "loss: 0.353  gen_loss: 0.451\n",
      "loss: 0.352  gen_loss: 0.451\n",
      "loss: 0.351  gen_loss: 0.452\n",
      "loss: 0.350  gen_loss: 0.452\n",
      "loss: 0.349  gen_loss: 0.452\n",
      "loss: 0.348  gen_loss: 0.453\n",
      "loss: 0.348  gen_loss: 0.453\n",
      "loss: 0.347  gen_loss: 0.453\n",
      "loss: 0.346  gen_loss: 0.453\n",
      "loss: 0.344  gen_loss: 0.453\n",
      "loss: 0.343  gen_loss: 0.453\n",
      "loss: 0.342  gen_loss: 0.453\n",
      "loss: 0.341  gen_loss: 0.452\n",
      "loss: 0.340  gen_loss: 0.452\n",
      "loss: 0.339  gen_loss: 0.451\n",
      "loss: 0.337  gen_loss: 0.450\n",
      "loss: 0.336  gen_loss: 0.448\n",
      "loss: 0.335  gen_loss: 0.447\n",
      "STEP:  35\n",
      "loss: 0.335  gen_loss: 0.445\n",
      "loss: 0.334  gen_loss: 0.443\n",
      "loss: 0.334  gen_loss: 0.441\n",
      "loss: 0.334  gen_loss: 0.437\n",
      "loss: 0.333  gen_loss: 0.435\n",
      "loss: 0.333  gen_loss: 0.433\n",
      "loss: 0.333  gen_loss: 0.430\n",
      "loss: 0.333  gen_loss: 0.427\n",
      "loss: 0.333  gen_loss: 0.424\n",
      "loss: 0.334  gen_loss: 0.421\n",
      "loss: 0.334  gen_loss: 0.418\n",
      "loss: 0.333  gen_loss: 0.414\n",
      "loss: 0.333  gen_loss: 0.411\n",
      "loss: 0.333  gen_loss: 0.408\n",
      "loss: 0.333  gen_loss: 0.405\n",
      "loss: 0.333  gen_loss: 0.402\n",
      "loss: 0.332  gen_loss: 0.399\n",
      "loss: 0.332  gen_loss: 0.397\n",
      "loss: 0.332  gen_loss: 0.395\n",
      "loss: 0.332  gen_loss: 0.393\n",
      "STEP:  36\n",
      "loss: 0.332  gen_loss: 0.392\n",
      "loss: 0.332  gen_loss: 0.391\n",
      "loss: 0.332  gen_loss: 0.390\n",
      "loss: 0.332  gen_loss: 0.389\n",
      "loss: 0.332  gen_loss: 0.388\n",
      "loss: 0.332  gen_loss: 0.387\n",
      "loss: 0.332  gen_loss: 0.386\n",
      "loss: 0.332  gen_loss: 0.385\n",
      "loss: 0.332  gen_loss: 0.384\n",
      "loss: 0.332  gen_loss: 0.383\n",
      "loss: 0.332  gen_loss: 0.383\n",
      "loss: 0.332  gen_loss: 0.382\n",
      "loss: 0.333  gen_loss: 0.381\n",
      "loss: 0.333  gen_loss: 0.380\n",
      "loss: 0.333  gen_loss: 0.379\n",
      "loss: 0.333  gen_loss: 0.378\n",
      "loss: 0.333  gen_loss: 0.377\n",
      "loss: 0.334  gen_loss: 0.375\n",
      "loss: 0.334  gen_loss: 0.374\n",
      "loss: 0.334  gen_loss: 0.373\n",
      "STEP:  37\n",
      "loss: 0.335  gen_loss: 0.372\n",
      "loss: 0.335  gen_loss: 0.371\n",
      "loss: 0.335  gen_loss: 0.369\n",
      "loss: 0.336  gen_loss: 0.367\n",
      "loss: 0.337  gen_loss: 0.366\n",
      "loss: 0.338  gen_loss: 0.364\n",
      "loss: 0.338  gen_loss: 0.362\n",
      "loss: 0.340  gen_loss: 0.359\n",
      "loss: 0.340  gen_loss: 0.357\n",
      "loss: 0.341  gen_loss: 0.354\n",
      "loss: 0.343  gen_loss: 0.351\n",
      "loss: 0.344  gen_loss: 0.347\n",
      "loss: 0.345  gen_loss: 0.343\n",
      "loss: 0.347  gen_loss: 0.338\n",
      "loss: 0.348  gen_loss: 0.333\n",
      "loss: 0.348  gen_loss: 0.330\n",
      "loss: 0.348  gen_loss: 0.327\n",
      "loss: 0.348  gen_loss: 0.324\n",
      "loss: 0.348  gen_loss: 0.321\n",
      "loss: 0.350  gen_loss: 0.315\n",
      "STEP:  38\n",
      "loss: 0.349  gen_loss: 0.312\n",
      "loss: 0.349  gen_loss: 0.310\n",
      "loss: 0.349  gen_loss: 0.307\n",
      "loss: 0.349  gen_loss: 0.304\n",
      "loss: 0.349  gen_loss: 0.301\n",
      "loss: 0.348  gen_loss: 0.298\n",
      "loss: 0.348  gen_loss: 0.296\n",
      "loss: 0.348  gen_loss: 0.294\n",
      "loss: 0.348  gen_loss: 0.292\n",
      "loss: 0.348  gen_loss: 0.290\n",
      "loss: 0.348  gen_loss: 0.289\n",
      "loss: 0.347  gen_loss: 0.287\n",
      "loss: 0.347  gen_loss: 0.286\n",
      "loss: 0.347  gen_loss: 0.285\n",
      "loss: 0.347  gen_loss: 0.283\n",
      "loss: 0.347  gen_loss: 0.282\n",
      "loss: 0.347  gen_loss: 0.280\n",
      "loss: 0.346  gen_loss: 0.278\n",
      "loss: 0.346  gen_loss: 0.276\n",
      "loss: 0.346  gen_loss: 0.274\n",
      "STEP:  39\n",
      "loss: 0.345  gen_loss: 0.272\n",
      "loss: 0.345  gen_loss: 0.271\n",
      "loss: 0.345  gen_loss: 0.269\n",
      "loss: 0.344  gen_loss: 0.268\n",
      "loss: 0.344  gen_loss: 0.266\n",
      "loss: 0.344  gen_loss: 0.265\n",
      "loss: 0.343  gen_loss: 0.264\n",
      "loss: 0.343  gen_loss: 0.263\n",
      "loss: 0.343  gen_loss: 0.262\n",
      "loss: 0.342  gen_loss: 0.262\n",
      "loss: 0.342  gen_loss: 0.261\n",
      "loss: 0.342  gen_loss: 0.261\n",
      "loss: 0.342  gen_loss: 0.260\n",
      "loss: 0.341  gen_loss: 0.260\n",
      "loss: 0.341  gen_loss: 0.259\n",
      "loss: 0.341  gen_loss: 0.259\n",
      "loss: 0.341  gen_loss: 0.259\n",
      "loss: 0.341  gen_loss: 0.258\n",
      "loss: 0.341  gen_loss: 0.258\n",
      "loss: 0.341  gen_loss: 0.258\n",
      "STEP:  40\n",
      "loss: 0.341  gen_loss: 0.257\n",
      "loss: 0.341  gen_loss: 0.257\n",
      "loss: 0.341  gen_loss: 0.256\n",
      "loss: 0.341  gen_loss: 0.256\n",
      "loss: 0.341  gen_loss: 0.255\n",
      "loss: 0.341  gen_loss: 0.255\n",
      "loss: 0.341  gen_loss: 0.254\n",
      "loss: 0.341  gen_loss: 0.254\n",
      "loss: 0.341  gen_loss: 0.253\n",
      "loss: 0.341  gen_loss: 0.252\n",
      "loss: 0.341  gen_loss: 0.251\n",
      "loss: 0.342  gen_loss: 0.250\n",
      "loss: 0.342  gen_loss: 0.249\n",
      "loss: 0.342  gen_loss: 0.248\n",
      "loss: 0.342  gen_loss: 0.248\n",
      "loss: 0.342  gen_loss: 0.247\n",
      "loss: 0.342  gen_loss: 0.246\n",
      "loss: 0.342  gen_loss: 0.245\n",
      "loss: 0.342  gen_loss: 0.244\n",
      "loss: 0.343  gen_loss: 0.242\n",
      "STEP:  41\n",
      "loss: 0.343  gen_loss: 0.241\n",
      "loss: 0.343  gen_loss: 0.240\n",
      "loss: 0.343  gen_loss: 0.239\n",
      "loss: 0.343  gen_loss: 0.237\n",
      "loss: 0.343  gen_loss: 0.236\n",
      "loss: 0.343  gen_loss: 0.235\n",
      "loss: 0.343  gen_loss: 0.233\n",
      "loss: 0.344  gen_loss: 0.232\n",
      "loss: 0.344  gen_loss: 0.231\n",
      "loss: 0.344  gen_loss: 0.230\n",
      "loss: 0.344  gen_loss: 0.228\n",
      "loss: 0.344  gen_loss: 0.227\n",
      "loss: 0.345  gen_loss: 0.226\n",
      "loss: 0.345  gen_loss: 0.225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.345  gen_loss: 0.223\n",
      "loss: 0.345  gen_loss: 0.222\n",
      "loss: 0.345  gen_loss: 0.221\n",
      "loss: 0.346  gen_loss: 0.220\n",
      "loss: 0.346  gen_loss: 0.219\n",
      "loss: 0.346  gen_loss: 0.217\n",
      "STEP:  42\n",
      "loss: 0.346  gen_loss: 0.216\n",
      "loss: 0.347  gen_loss: 0.214\n",
      "loss: 0.347  gen_loss: 0.213\n",
      "loss: 0.347  gen_loss: 0.212\n",
      "loss: 0.347  gen_loss: 0.212\n",
      "loss: 0.347  gen_loss: 0.211\n",
      "loss: 0.347  gen_loss: 0.210\n",
      "loss: 0.347  gen_loss: 0.209\n",
      "loss: 0.347  gen_loss: 0.208\n",
      "loss: 0.347  gen_loss: 0.207\n",
      "loss: 0.347  gen_loss: 0.206\n",
      "loss: 0.347  gen_loss: 0.205\n",
      "loss: 0.347  gen_loss: 0.204\n",
      "loss: 0.347  gen_loss: 0.203\n",
      "loss: 0.347  gen_loss: 0.202\n",
      "loss: 0.368  gen_loss: 0.193\n",
      "loss: 0.366  gen_loss: 0.192\n",
      "loss: 0.364  gen_loss: 0.191\n",
      "loss: 0.362  gen_loss: 0.191\n",
      "loss: 0.361  gen_loss: 0.190\n",
      "STEP:  43\n",
      "loss: 0.359  gen_loss: 0.190\n",
      "loss: 0.358  gen_loss: 0.189\n",
      "loss: 0.357  gen_loss: 0.189\n",
      "loss: 0.356  gen_loss: 0.189\n",
      "loss: 0.355  gen_loss: 0.188\n",
      "loss: 0.355  gen_loss: 0.188\n",
      "loss: 0.354  gen_loss: 0.188\n",
      "loss: 0.353  gen_loss: 0.188\n",
      "loss: 0.353  gen_loss: 0.187\n",
      "loss: 0.352  gen_loss: 0.187\n",
      "loss: 0.351  gen_loss: 0.187\n",
      "loss: 0.351  gen_loss: 0.186\n",
      "loss: 0.350  gen_loss: 0.186\n",
      "loss: 0.349  gen_loss: 0.185\n",
      "loss: 0.348  gen_loss: 0.185\n",
      "loss: 0.347  gen_loss: 0.185\n",
      "loss: 0.346  gen_loss: 0.184\n",
      "loss: 0.346  gen_loss: 0.183\n",
      "loss: 0.345  gen_loss: 0.183\n",
      "loss: 0.345  gen_loss: 0.182\n",
      "STEP:  44\n",
      "loss: 0.345  gen_loss: 0.181\n",
      "loss: 0.344  gen_loss: 0.180\n",
      "loss: 0.344  gen_loss: 0.179\n",
      "loss: 0.344  gen_loss: 0.177\n",
      "loss: 0.344  gen_loss: 0.176\n",
      "loss: 0.345  gen_loss: 0.175\n",
      "loss: 0.345  gen_loss: 0.174\n",
      "loss: 0.345  gen_loss: 0.172\n",
      "loss: 0.345  gen_loss: 0.171\n",
      "loss: 0.345  gen_loss: 0.170\n",
      "loss: 0.346  gen_loss: 0.169\n",
      "loss: 0.346  gen_loss: 0.168\n",
      "loss: 0.346  gen_loss: 0.167\n",
      "loss: 0.346  gen_loss: 0.166\n",
      "loss: 0.347  gen_loss: 0.165\n",
      "loss: 0.347  gen_loss: 0.165\n",
      "loss: 0.347  gen_loss: 0.164\n",
      "loss: 0.347  gen_loss: 0.163\n",
      "loss: 0.347  gen_loss: 0.162\n",
      "loss: 0.347  gen_loss: 0.162\n",
      "STEP:  45\n",
      "loss: 0.347  gen_loss: 0.161\n",
      "loss: 0.347  gen_loss: 0.161\n",
      "loss: 0.347  gen_loss: 0.160\n",
      "loss: 0.347  gen_loss: 0.160\n",
      "loss: 0.347  gen_loss: 0.160\n",
      "loss: 0.347  gen_loss: 0.159\n",
      "loss: 0.347  gen_loss: 0.159\n",
      "loss: 0.347  gen_loss: 0.159\n",
      "loss: 0.347  gen_loss: 0.158\n",
      "loss: 0.347  gen_loss: 0.157\n",
      "loss: 0.347  gen_loss: 0.157\n",
      "loss: 0.347  gen_loss: 0.156\n",
      "loss: 0.347  gen_loss: 0.155\n",
      "loss: 0.348  gen_loss: 0.155\n",
      "loss: 0.348  gen_loss: 0.154\n",
      "loss: 0.348  gen_loss: 0.153\n",
      "loss: 0.348  gen_loss: 0.152\n",
      "loss: 0.349  gen_loss: 0.151\n",
      "loss: 0.349  gen_loss: 0.150\n",
      "loss: 0.349  gen_loss: 0.149\n",
      "STEP:  46\n",
      "loss: 0.350  gen_loss: 0.147\n",
      "loss: 0.350  gen_loss: 0.146\n",
      "loss: 0.351  gen_loss: 0.145\n",
      "loss: 0.351  gen_loss: 0.143\n",
      "loss: 0.352  gen_loss: 0.142\n",
      "loss: 0.352  gen_loss: 0.140\n",
      "loss: 0.353  gen_loss: 0.139\n",
      "loss: 0.354  gen_loss: 0.137\n",
      "loss: 0.354  gen_loss: 0.136\n",
      "loss: 0.355  gen_loss: 0.135\n",
      "loss: 0.356  gen_loss: 0.133\n",
      "loss: 0.356  gen_loss: 0.132\n",
      "loss: 0.357  gen_loss: 0.131\n",
      "loss: 0.358  gen_loss: 0.129\n",
      "loss: 0.358  gen_loss: 0.128\n",
      "loss: 0.359  gen_loss: 0.127\n",
      "loss: 0.359  gen_loss: 0.126\n",
      "loss: 0.360  gen_loss: 0.124\n",
      "loss: 0.360  gen_loss: 0.123\n",
      "loss: 0.361  gen_loss: 0.122\n",
      "STEP:  47\n",
      "loss: 0.361  gen_loss: 0.121\n",
      "loss: 0.361  gen_loss: 0.120\n",
      "loss: 0.361  gen_loss: 0.120\n",
      "loss: 0.362  gen_loss: 0.119\n",
      "loss: 0.362  gen_loss: 0.119\n",
      "loss: 0.362  gen_loss: 0.118\n",
      "loss: 0.362  gen_loss: 0.118\n",
      "loss: 0.362  gen_loss: 0.117\n",
      "loss: 0.362  gen_loss: 0.117\n",
      "loss: 0.362  gen_loss: 0.117\n",
      "loss: 0.362  gen_loss: 0.116\n",
      "loss: 0.362  gen_loss: 0.116\n",
      "loss: 0.362  gen_loss: 0.116\n",
      "loss: 0.361  gen_loss: 0.116\n",
      "loss: 0.361  gen_loss: 0.115\n",
      "loss: 0.361  gen_loss: 0.115\n",
      "loss: 0.361  gen_loss: 0.115\n",
      "loss: 0.361  gen_loss: 0.115\n",
      "loss: 0.361  gen_loss: 0.114\n",
      "loss: 0.360  gen_loss: 0.114\n",
      "STEP:  48\n",
      "loss: 0.360  gen_loss: 0.114\n",
      "loss: 0.360  gen_loss: 0.114\n",
      "loss: 0.359  gen_loss: 0.113\n",
      "loss: 0.359  gen_loss: 0.113\n",
      "loss: 0.358  gen_loss: 0.112\n",
      "loss: 0.358  gen_loss: 0.112\n",
      "loss: 0.357  gen_loss: 0.111\n",
      "loss: 0.356  gen_loss: 0.111\n",
      "loss: 0.355  gen_loss: 0.110\n",
      "loss: 0.354  gen_loss: 0.110\n",
      "loss: 0.353  gen_loss: 0.109\n",
      "loss: 0.352  gen_loss: 0.109\n",
      "loss: 0.351  gen_loss: 0.108\n",
      "loss: 0.350  gen_loss: 0.108\n",
      "loss: 0.348  gen_loss: 0.108\n",
      "loss: 0.347  gen_loss: 0.107\n",
      "loss: 0.346  gen_loss: 0.107\n",
      "loss: 0.345  gen_loss: 0.107\n",
      "loss: 0.344  gen_loss: 0.106\n",
      "loss: 0.342  gen_loss: 0.106\n",
      "STEP:  49\n",
      "loss: 0.341  gen_loss: 0.106\n",
      "loss: 0.340  gen_loss: 0.106\n",
      "loss: 0.339  gen_loss: 0.105\n",
      "loss: 0.339  gen_loss: 0.105\n",
      "loss: 0.338  gen_loss: 0.105\n",
      "loss: 0.337  gen_loss: 0.105\n",
      "loss: 0.337  gen_loss: 0.104\n",
      "loss: 0.336  gen_loss: 0.104\n",
      "loss: 0.336  gen_loss: 0.103\n",
      "loss: 0.335  gen_loss: 0.103\n",
      "loss: 0.335  gen_loss: 0.102\n",
      "loss: 0.335  gen_loss: 0.101\n",
      "loss: 0.334  gen_loss: 0.101\n",
      "loss: 0.334  gen_loss: 0.100\n",
      "loss: 0.334  gen_loss: 0.099\n",
      "loss: 0.334  gen_loss: 0.099\n",
      "loss: 0.334  gen_loss: 0.098\n",
      "loss: 0.333  gen_loss: 0.098\n",
      "loss: 0.333  gen_loss: 0.097\n",
      "loss: 0.333  gen_loss: 0.097\n",
      "STEP:  50\n",
      "loss: 0.333  gen_loss: 0.096\n",
      "loss: 0.333  gen_loss: 0.096\n",
      "loss: 0.333  gen_loss: 0.095\n",
      "loss: 0.333  gen_loss: 0.095\n",
      "loss: 0.333  gen_loss: 0.095\n",
      "loss: 0.333  gen_loss: 0.094\n",
      "loss: 0.333  gen_loss: 0.094\n",
      "loss: 0.333  gen_loss: 0.094\n",
      "loss: 0.333  gen_loss: 0.093\n",
      "loss: 0.333  gen_loss: 0.093\n",
      "loss: 0.333  gen_loss: 0.092\n",
      "loss: 0.333  gen_loss: 0.092\n",
      "loss: 0.333  gen_loss: 0.092\n",
      "loss: 0.333  gen_loss: 0.091\n",
      "loss: 0.333  gen_loss: 0.091\n",
      "loss: 0.333  gen_loss: 0.090\n",
      "loss: 0.333  gen_loss: 0.090\n",
      "loss: 0.333  gen_loss: 0.089\n",
      "loss: 0.332  gen_loss: 0.089\n",
      "loss: 0.332  gen_loss: 0.089\n",
      "STEP:  51\n",
      "loss: 0.332  gen_loss: 0.088\n",
      "loss: 0.332  gen_loss: 0.088\n",
      "loss: 0.332  gen_loss: 0.087\n",
      "loss: 0.332  gen_loss: 0.087\n",
      "loss: 0.331  gen_loss: 0.086\n",
      "loss: 0.331  gen_loss: 0.086\n",
      "loss: 0.331  gen_loss: 0.085\n",
      "loss: 0.331  gen_loss: 0.085\n",
      "loss: 0.331  gen_loss: 0.084\n",
      "loss: 0.330  gen_loss: 0.084\n",
      "loss: 0.330  gen_loss: 0.083\n",
      "loss: 0.330  gen_loss: 0.083\n",
      "loss: 0.329  gen_loss: 0.083\n",
      "loss: 0.329  gen_loss: 0.082\n",
      "loss: 0.329  gen_loss: 0.082\n",
      "loss: 0.329  gen_loss: 0.081\n",
      "loss: 0.328  gen_loss: 0.081\n",
      "loss: 0.328  gen_loss: 0.080\n",
      "loss: 0.328  gen_loss: 0.080\n",
      "loss: 0.328  gen_loss: 0.079\n",
      "STEP:  52\n",
      "loss: 0.328  gen_loss: 0.079\n",
      "loss: 0.328  gen_loss: 0.078\n",
      "loss: 0.328  gen_loss: 0.078\n",
      "loss: 0.328  gen_loss: 0.078\n",
      "loss: 0.328  gen_loss: 0.077\n",
      "loss: 0.328  gen_loss: 0.077\n",
      "loss: 0.328  gen_loss: 0.076\n",
      "loss: 0.328  gen_loss: 0.076\n",
      "loss: 0.328  gen_loss: 0.075\n",
      "loss: 0.328  gen_loss: 0.075\n",
      "loss: 0.328  gen_loss: 0.075\n",
      "loss: 0.328  gen_loss: 0.074\n",
      "loss: 0.328  gen_loss: 0.074\n",
      "loss: 0.328  gen_loss: 0.074\n",
      "loss: 0.328  gen_loss: 0.073\n",
      "loss: 0.327  gen_loss: 0.073\n",
      "loss: 0.327  gen_loss: 0.073\n",
      "loss: 0.327  gen_loss: 0.072\n",
      "loss: 0.326  gen_loss: 0.072\n",
      "loss: 0.326  gen_loss: 0.072\n",
      "STEP:  53\n",
      "loss: 0.325  gen_loss: 0.072\n",
      "loss: 0.325  gen_loss: 0.072\n",
      "loss: 0.324  gen_loss: 0.071\n",
      "loss: 0.323  gen_loss: 0.071\n",
      "loss: 0.323  gen_loss: 0.071\n",
      "loss: 0.322  gen_loss: 0.071\n",
      "loss: 0.322  gen_loss: 0.071\n",
      "loss: 0.321  gen_loss: 0.070\n",
      "loss: 0.321  gen_loss: 0.070\n",
      "loss: 0.320  gen_loss: 0.070\n",
      "loss: 0.320  gen_loss: 0.070\n",
      "loss: 0.319  gen_loss: 0.070\n",
      "loss: 0.318  gen_loss: 0.070\n",
      "loss: 0.318  gen_loss: 0.070\n",
      "loss: 0.317  gen_loss: 0.069\n",
      "loss: 0.317  gen_loss: 0.069\n",
      "loss: 0.316  gen_loss: 0.069\n",
      "loss: 0.315  gen_loss: 0.069\n",
      "loss: 0.315  gen_loss: 0.069\n",
      "loss: 0.314  gen_loss: 0.069\n",
      "STEP:  54\n",
      "loss: 0.314  gen_loss: 0.069\n",
      "loss: 0.314  gen_loss: 0.069\n",
      "loss: 0.313  gen_loss: 0.069\n",
      "loss: 0.313  gen_loss: 0.069\n",
      "loss: 0.313  gen_loss: 0.069\n",
      "loss: 0.312  gen_loss: 0.069\n",
      "loss: 0.312  gen_loss: 0.069\n",
      "loss: 0.312  gen_loss: 0.069\n",
      "loss: 0.312  gen_loss: 0.069\n",
      "loss: 0.311  gen_loss: 0.068\n",
      "loss: 0.311  gen_loss: 0.068\n",
      "loss: 0.311  gen_loss: 0.068\n",
      "loss: 0.311  gen_loss: 0.067\n",
      "loss: 0.311  gen_loss: 0.067\n",
      "loss: 0.310  gen_loss: 0.067\n",
      "loss: 0.310  gen_loss: 0.066\n",
      "loss: 0.310  gen_loss: 0.066\n",
      "loss: 0.310  gen_loss: 0.065\n",
      "loss: 0.310  gen_loss: 0.065\n",
      "loss: 0.310  gen_loss: 0.064\n",
      "STEP:  55\n",
      "loss: 0.310  gen_loss: 0.063\n",
      "loss: 0.311  gen_loss: 0.063\n",
      "loss: 0.311  gen_loss: 0.062\n",
      "loss: 0.311  gen_loss: 0.062\n",
      "loss: 0.311  gen_loss: 0.061\n",
      "loss: 0.311  gen_loss: 0.060\n",
      "loss: 0.311  gen_loss: 0.060\n",
      "loss: 0.311  gen_loss: 0.059\n",
      "loss: 0.311  gen_loss: 0.059\n",
      "loss: 0.312  gen_loss: 0.059\n",
      "loss: 0.312  gen_loss: 0.058\n",
      "loss: 0.312  gen_loss: 0.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.312  gen_loss: 0.058\n",
      "loss: 0.312  gen_loss: 0.057\n",
      "loss: 0.312  gen_loss: 0.057\n",
      "loss: 0.312  gen_loss: 0.057\n",
      "loss: 0.312  gen_loss: 0.057\n",
      "loss: 0.312  gen_loss: 0.057\n",
      "loss: 0.312  gen_loss: 0.056\n",
      "loss: 0.312  gen_loss: 0.056\n",
      "STEP:  56\n",
      "loss: 0.312  gen_loss: 0.056\n",
      "loss: 0.312  gen_loss: 0.056\n",
      "loss: 0.312  gen_loss: 0.056\n",
      "loss: 0.312  gen_loss: 0.056\n",
      "loss: 0.312  gen_loss: 0.055\n",
      "loss: 0.312  gen_loss: 0.055\n",
      "loss: 0.312  gen_loss: 0.055\n",
      "loss: 0.312  gen_loss: 0.055\n",
      "loss: 0.312  gen_loss: 0.055\n",
      "loss: 0.312  gen_loss: 0.055\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.311  gen_loss: 0.054\n",
      "loss: 0.310  gen_loss: 0.053\n",
      "loss: 0.310  gen_loss: 0.053\n",
      "STEP:  57\n",
      "loss: 0.310  gen_loss: 0.053\n",
      "loss: 0.310  gen_loss: 0.053\n",
      "loss: 0.310  gen_loss: 0.053\n",
      "loss: 0.310  gen_loss: 0.053\n",
      "loss: 0.309  gen_loss: 0.053\n",
      "loss: 0.309  gen_loss: 0.053\n",
      "loss: 0.309  gen_loss: 0.053\n",
      "loss: 0.309  gen_loss: 0.053\n",
      "loss: 0.308  gen_loss: 0.053\n",
      "loss: 0.308  gen_loss: 0.053\n",
      "loss: 0.308  gen_loss: 0.053\n",
      "loss: 0.308  gen_loss: 0.053\n",
      "loss: 0.308  gen_loss: 0.053\n",
      "loss: 0.308  gen_loss: 0.052\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "STEP:  58\n",
      "loss: 0.307  gen_loss: 0.052\n",
      "loss: 0.306  gen_loss: 0.052\n",
      "loss: 0.306  gen_loss: 0.051\n",
      "loss: 0.306  gen_loss: 0.051\n",
      "loss: 0.306  gen_loss: 0.051\n",
      "loss: 0.306  gen_loss: 0.051\n",
      "loss: 0.306  gen_loss: 0.051\n",
      "loss: 0.306  gen_loss: 0.051\n",
      "loss: 0.306  gen_loss: 0.050\n",
      "loss: 0.306  gen_loss: 0.050\n",
      "loss: 0.306  gen_loss: 0.050\n",
      "loss: 0.305  gen_loss: 0.050\n",
      "loss: 0.305  gen_loss: 0.049\n",
      "loss: 0.305  gen_loss: 0.049\n",
      "loss: 0.305  gen_loss: 0.049\n",
      "loss: 0.305  gen_loss: 0.049\n",
      "loss: 0.305  gen_loss: 0.048\n",
      "loss: 0.305  gen_loss: 0.048\n",
      "loss: 0.305  gen_loss: 0.048\n",
      "loss: 0.305  gen_loss: 0.048\n",
      "STEP:  59\n",
      "loss: 0.305  gen_loss: 0.047\n",
      "loss: 0.305  gen_loss: 0.047\n",
      "loss: 0.305  gen_loss: 0.047\n",
      "loss: 0.305  gen_loss: 0.047\n",
      "loss: 0.305  gen_loss: 0.047\n",
      "loss: 0.305  gen_loss: 0.046\n",
      "loss: 0.305  gen_loss: 0.046\n",
      "loss: 0.305  gen_loss: 0.046\n",
      "loss: 0.305  gen_loss: 0.046\n",
      "loss: 0.305  gen_loss: 0.046\n",
      "loss: 0.305  gen_loss: 0.045\n",
      "loss: 0.305  gen_loss: 0.045\n",
      "loss: 0.305  gen_loss: 0.045\n",
      "loss: 0.305  gen_loss: 0.045\n",
      "loss: 0.305  gen_loss: 0.045\n",
      "loss: 0.305  gen_loss: 0.044\n",
      "loss: 0.305  gen_loss: 0.044\n",
      "loss: 0.305  gen_loss: 0.044\n",
      "loss: 0.305  gen_loss: 0.044\n",
      "loss: 0.305  gen_loss: 0.044\n",
      "STEP:  60\n",
      "loss: 0.305  gen_loss: 0.043\n",
      "loss: 0.305  gen_loss: 0.043\n",
      "loss: 0.305  gen_loss: 0.043\n",
      "loss: 0.305  gen_loss: 0.043\n",
      "loss: 0.305  gen_loss: 0.043\n",
      "loss: 0.305  gen_loss: 0.042\n",
      "loss: 0.305  gen_loss: 0.042\n",
      "loss: 0.305  gen_loss: 0.042\n",
      "loss: 0.305  gen_loss: 0.042\n",
      "loss: 0.305  gen_loss: 0.042\n",
      "loss: 0.305  gen_loss: 0.041\n",
      "loss: 0.305  gen_loss: 0.041\n",
      "loss: 0.305  gen_loss: 0.041\n",
      "loss: 0.305  gen_loss: 0.041\n",
      "loss: 0.305  gen_loss: 0.040\n",
      "loss: 0.305  gen_loss: 0.040\n",
      "loss: 0.305  gen_loss: 0.040\n",
      "loss: 0.305  gen_loss: 0.040\n",
      "loss: 0.304  gen_loss: 0.039\n",
      "loss: 0.304  gen_loss: 0.039\n",
      "STEP:  61\n",
      "loss: 0.305  gen_loss: 0.039\n",
      "loss: 0.305  gen_loss: 0.039\n",
      "loss: 0.305  gen_loss: 0.039\n",
      "loss: 0.305  gen_loss: 0.039\n",
      "loss: 0.304  gen_loss: 0.039\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "loss: 0.304  gen_loss: 0.038\n",
      "STEP:  62\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.304  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "STEP:  63\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.037\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.303  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.302  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "STEP:  64\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.301  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.300  gen_loss: 0.036\n",
      "loss: 0.299  gen_loss: 0.036\n",
      "loss: 0.299  gen_loss: 0.036\n",
      "loss: 0.299  gen_loss: 0.036\n",
      "loss: 0.299  gen_loss: 0.037\n",
      "loss: 0.299  gen_loss: 0.037\n",
      "loss: 0.299  gen_loss: 0.037\n",
      "STEP:  65\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "STEP:  66\n",
      "loss: 0.298  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.297  gen_loss: 0.037\n",
      "loss: 0.296  gen_loss: 0.037\n",
      "loss: 0.296  gen_loss: 0.037\n",
      "loss: 0.296  gen_loss: 0.037\n",
      "loss: 0.296  gen_loss: 0.037\n",
      "STEP:  67\n",
      "loss: 0.296  gen_loss: 0.037\n",
      "loss: 0.296  gen_loss: 0.037\n",
      "loss: 0.296  gen_loss: 0.036\n",
      "loss: 0.296  gen_loss: 0.036\n",
      "loss: 0.296  gen_loss: 0.036\n",
      "loss: 0.296  gen_loss: 0.036\n",
      "loss: 0.296  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.036\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "STEP:  68\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.035\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "STEP:  69\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.034\n",
      "loss: 0.295  gen_loss: 0.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.296  gen_loss: 0.033\n",
      "STEP:  70\n",
      "loss: 0.295  gen_loss: 0.033\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.032\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "loss: 0.296  gen_loss: 0.031\n",
      "STEP:  71\n",
      "loss: 0.295  gen_loss: 0.031\n",
      "loss: 0.295  gen_loss: 0.031\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.295  gen_loss: 0.030\n",
      "loss: 0.294  gen_loss: 0.030\n",
      "loss: 0.294  gen_loss: 0.030\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "STEP:  72\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.294  gen_loss: 0.029\n",
      "loss: 0.293  gen_loss: 0.029\n",
      "loss: 0.293  gen_loss: 0.029\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "STEP:  73\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.293  gen_loss: 0.028\n",
      "loss: 0.292  gen_loss: 0.028\n",
      "loss: 0.292  gen_loss: 0.028\n",
      "loss: 0.292  gen_loss: 0.028\n",
      "loss: 0.292  gen_loss: 0.028\n",
      "loss: 0.292  gen_loss: 0.028\n",
      "loss: 0.292  gen_loss: 0.028\n",
      "loss: 0.291  gen_loss: 0.028\n",
      "STEP:  74\n",
      "loss: 0.291  gen_loss: 0.028\n",
      "loss: 0.291  gen_loss: 0.028\n",
      "loss: 0.291  gen_loss: 0.028\n",
      "loss: 0.290  gen_loss: 0.028\n",
      "loss: 0.290  gen_loss: 0.028\n",
      "loss: 0.290  gen_loss: 0.028\n",
      "loss: 0.290  gen_loss: 0.028\n",
      "loss: 0.290  gen_loss: 0.028\n",
      "loss: 0.289  gen_loss: 0.028\n",
      "loss: 0.289  gen_loss: 0.028\n",
      "loss: 0.289  gen_loss: 0.028\n",
      "loss: 0.289  gen_loss: 0.028\n",
      "loss: 0.289  gen_loss: 0.028\n",
      "loss: 0.289  gen_loss: 0.028\n",
      "loss: 0.288  gen_loss: 0.028\n",
      "loss: 0.288  gen_loss: 0.028\n",
      "loss: 0.288  gen_loss: 0.028\n",
      "loss: 0.288  gen_loss: 0.028\n",
      "loss: 0.288  gen_loss: 0.027\n",
      "loss: 0.288  gen_loss: 0.027\n",
      "STEP:  75\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.287  gen_loss: 0.027\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "loss: 0.286  gen_loss: 0.026\n",
      "STEP:  76\n",
      "loss: 0.286  gen_loss: 0.025\n",
      "loss: 0.286  gen_loss: 0.025\n",
      "loss: 0.286  gen_loss: 0.025\n",
      "loss: 0.286  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.026\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "STEP:  77\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.025\n",
      "loss: 0.285  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "STEP:  78\n",
      "loss: 0.284  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "STEP:  79\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.024\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.283  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "STEP:  80\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.282  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.023\n",
      "loss: 0.281  gen_loss: 0.024\n",
      "STEP:  81\n",
      "loss: 0.281  gen_loss: 0.024\n",
      "loss: 0.281  gen_loss: 0.024\n",
      "loss: 0.281  gen_loss: 0.024\n",
      "loss: 0.281  gen_loss: 0.024\n",
      "loss: 0.281  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "STEP:  82\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.280  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.279  gen_loss: 0.024\n",
      "loss: 0.278  gen_loss: 0.024\n",
      "loss: 0.278  gen_loss: 0.024\n",
      "loss: 0.278  gen_loss: 0.023\n",
      "loss: 0.278  gen_loss: 0.023\n",
      "STEP:  83\n",
      "loss: 0.278  gen_loss: 0.023\n",
      "loss: 0.278  gen_loss: 0.023\n",
      "loss: 0.278  gen_loss: 0.023\n",
      "loss: 0.277  gen_loss: 0.023\n",
      "loss: 0.277  gen_loss: 0.023\n",
      "loss: 0.277  gen_loss: 0.023\n",
      "loss: 0.277  gen_loss: 0.023\n",
      "loss: 0.277  gen_loss: 0.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.277  gen_loss: 0.022\n",
      "loss: 0.277  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "loss: 0.276  gen_loss: 0.022\n",
      "STEP:  84\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.275  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "STEP:  85\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.274  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "STEP:  86\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.273  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.272  gen_loss: 0.022\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "STEP:  87\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "loss: 0.271  gen_loss: 0.022\n",
      "loss: 0.270  gen_loss: 0.022\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.270  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "STEP:  88\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.021\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.269  gen_loss: 0.022\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "STEP:  89\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.268  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "STEP:  90\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.267  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "STEP:  91\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.266  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "STEP:  92\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.021\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "STEP:  93\n",
      "loss: 0.265  gen_loss: 0.020\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.265  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "STEP:  94\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.264  gen_loss: 0.019\n",
      "loss: 0.263  gen_loss: 0.019\n",
      "loss: 0.263  gen_loss: 0.019\n",
      "loss: 0.263  gen_loss: 0.019\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "STEP:  95\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.263  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.262  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.018\n",
      "loss: 0.261  gen_loss: 0.017\n",
      "STEP:  96\n",
      "loss: 0.261  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.260  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "STEP:  97\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.259  gen_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.259  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.258  gen_loss: 0.017\n",
      "loss: 0.257  gen_loss: 0.017\n",
      "loss: 0.257  gen_loss: 0.017\n",
      "loss: 0.257  gen_loss: 0.017\n",
      "STEP:  98\n",
      "loss: 0.257  gen_loss: 0.017\n",
      "loss: 0.257  gen_loss: 0.017\n",
      "loss: 0.257  gen_loss: 0.017\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "STEP:  99\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.257  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n",
      "loss: 0.256  gen_loss: 0.016\n"
     ]
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 构建网络\n",
    "lstm = lstm().double()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.LBFGS(lstm.parameters(), lr=0.1)\n",
    "\n",
    "# 开始训练    \n",
    "for i in range(100):\n",
    "    print('STEP: ', i)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = lstm(xtrain)\n",
    "        loss = criterion(out, ytrain)\n",
    "        print('loss: %5.3f  ' %(loss.item()), end=\"\")\n",
    "        loss.backward()\n",
    "        \n",
    "        out_gen = lstm(gen_xtrain)\n",
    "        loss_gen = criterion(out_gen, gen_ytrain)\n",
    "        print('gen_loss: %5.3f' % (loss_gen.item()))\n",
    "        loss_gen.backward()\n",
    "        \n",
    "        return loss + loss_gen\n",
    "    \n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.30901459165520456\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    future = 0\n",
    "    pred = lstm(xtest, future=future)\n",
    "    loss = criterion(ytest, pred)\n",
    "    print('test loss:', loss.item())\n",
    "\n",
    "pred_data = pred.detach().numpy()\n",
    "test_data = ytest.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从每个batch的序列数据中提取出ground truth和预测值\n",
    "\n",
    "gd_truth = []\n",
    "pred_val = []\n",
    "\n",
    "# 每个batch的序列数据中的最后一个是新来的数据，将每个batch中新来的值提取出来\n",
    "for i in range(len(pred_data)):\n",
    "    gd_truth.append(test_data[i][-1])\n",
    "    pred_val.append(pred_data[i][-1])\n",
    "    \n",
    "gd_truth = np.array(gd_truth)\n",
    "pred_val = np.array(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.78 18.32 16.72 16.8  16.49 16.72 16.89 16.73 15.48 15.08 14.47 15.04\n",
      " 14.74 14.62 14.9  15.33 14.7  14.98 15.03 15.16 15.44 15.24 15.35 15.22\n",
      " 15.72 15.36 15.19 14.62 14.43 14.34 13.73 13.86 13.61 13.35 13.49]\n",
      "[17.694472   18.64606454 18.29087208 16.65862202 16.81414712 16.5847933\n",
      " 17.15946596 17.09750203 16.73083864 15.48599821 14.92896296 14.2722588\n",
      " 15.02517659 14.94430043 14.59139237 14.76523443 15.30396031 14.76175513\n",
      " 15.06288595 15.09659787 15.04753438 15.32936647 15.23458465 15.33868213\n",
      " 15.23071494 15.49826058 15.3214282  15.12657018 14.59000755 14.5683802\n",
      " 14.24169628 13.76019165 13.94411208 13.91521566 13.35601689]\n"
     ]
    }
   ],
   "source": [
    "print(gd_truth)\n",
    "print(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0284433006763543"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欧式距离\n",
    "\n",
    "np.linalg.norm(gd_truth - pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gd_truth, label='true values')\n",
    "plt.plot(pred_val, label='predicted  values')\n",
    "plt.legend()\n",
    "plt.title('test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
