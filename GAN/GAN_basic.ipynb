{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文使用GAN来训练一个能生成一组符合高斯分布的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯分布的参数定义如下，每次生成30个符合高斯分布的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = 3.0\n",
    "data_stddev = 0.4\n",
    "Series_Length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面两个函数分别从高斯分布，0-1均匀分布中采样，返回可以生成$m\\times n$ tensor的函数。前者用于生成真实样本，后者用于生成输入Generator的噪声。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_sampler(mu, sigma):\n",
    "    dist = Normal(mu, sigma)\n",
    "    return lambda m, n: dist.sample((m, n)).requires_grad_()\n",
    "\n",
    "def get_noise_sampler():\n",
    "    return lambda m, n: torch.rand(m, n).requires_grad_()\n",
    "\n",
    "actual_data = get_real_sampler(data_mean, data_stddev)\n",
    "noise_data = get_noise_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面定义两个子网络的结构：Generator和Discriminator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.xfer = torch.nn.SELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.xfer(self.map1(x))\n",
    "        x = self.xfer(self.map2(x))\n",
    "        return self.xfer(self.map3(x))\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.elu = torch.nn.ELU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.map1(x))\n",
    "        x = self.elu(self.map2(x))\n",
    "        return torch.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面实例化网络，并定义损失函数，优化函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_input_size = 20    \n",
    "g_hidden_size = 150  \n",
    "g_output_size = Series_Length\n",
    "\n",
    "d_input_size = Series_Length\n",
    "d_hidden_size = 75   \n",
    "d_output_size = 1\n",
    "\n",
    "d_learning_rate = 3e-3\n",
    "g_learning_rate = 8e-3\n",
    "\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "\n",
    "d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate ) \n",
    "g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始训练，每轮交替训练Discriminator和Generator："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./GAN_algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意！在开始的若干轮中，Generator还比较弱，所以$D(G(Z^{(i)}))\\rightarrow 0$，所以$log(1-D(G(Z^{(i)})))\\rightarrow 0$。为了缓解这个问题，后面我都将$log(1-D(G(Z^{(i)})))$替换为$-log(D(G(Z^{(i)})))$，事实证明这样效果很好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.D Loss on real date 0.567\n",
      "Epoch 0.G Loss 0.703\n",
      "Epoch 50.D Loss on real date 0.094\n",
      "Epoch 50.G Loss 0.559\n",
      "Epoch 100.D Loss on real date 0.079\n",
      "Epoch 100.G Loss 0.542\n",
      "Epoch 150.D Loss on real date 0.115\n",
      "Epoch 150.G Loss 0.596\n",
      "Epoch 200.D Loss on real date 0.181\n",
      "Epoch 200.G Loss 0.641\n",
      "Epoch 250.D Loss on real date 0.223\n",
      "Epoch 250.G Loss 0.571\n",
      "Epoch 300.D Loss on real date 0.261\n",
      "Epoch 300.G Loss 0.519\n",
      "Epoch 350.D Loss on real date 0.318\n",
      "Epoch 350.G Loss 0.467\n",
      "Epoch 400.D Loss on real date 0.381\n",
      "Epoch 400.G Loss 0.443\n",
      "Epoch 450.D Loss on real date 0.257\n",
      "Epoch 450.G Loss 0.169\n",
      "Epoch 500.D Loss on real date 0.083\n",
      "Epoch 500.G Loss 0.037\n",
      "Epoch 550.D Loss on real date 0.038\n",
      "Epoch 550.G Loss 0.009\n",
      "Epoch 600.D Loss on real date 0.021\n",
      "Epoch 600.G Loss 0.006\n",
      "Epoch 650.D Loss on real date 0.015\n",
      "Epoch 650.G Loss 0.003\n",
      "Epoch 700.D Loss on real date 0.010\n",
      "Epoch 700.G Loss 0.003\n",
      "Epoch 750.D Loss on real date 0.008\n",
      "Epoch 750.G Loss 0.001\n",
      "Epoch 800.D Loss on real date 0.007\n",
      "Epoch 800.G Loss 0.002\n",
      "Epoch 850.D Loss on real date 0.005\n",
      "Epoch 850.G Loss 0.001\n",
      "Epoch 900.D Loss on real date 0.005\n",
      "Epoch 900.G Loss 0.001\n",
      "Epoch 950.D Loss on real date 0.004\n",
      "Epoch 950.G Loss 0.001\n",
      "Epoch 1000.D Loss on real date 0.004\n",
      "Epoch 1000.G Loss 0.001\n",
      "Epoch 1050.D Loss on real date 0.003\n",
      "Epoch 1050.G Loss 0.000\n",
      "Epoch 1100.D Loss on real date 0.003\n",
      "Epoch 1100.G Loss 0.000\n",
      "Epoch 1150.D Loss on real date 0.003\n",
      "Epoch 1150.G Loss 0.000\n",
      "Epoch 1200.D Loss on real date 0.002\n",
      "Epoch 1200.G Loss 0.000\n",
      "Epoch 1250.D Loss on real date 0.002\n",
      "Epoch 1250.G Loss 0.000\n",
      "Epoch 1300.D Loss on real date 0.002\n",
      "Epoch 1300.G Loss 0.000\n",
      "Epoch 1350.D Loss on real date 0.002\n",
      "Epoch 1350.G Loss 0.000\n",
      "Epoch 1400.D Loss on real date 0.002\n",
      "Epoch 1400.G Loss 0.000\n",
      "Epoch 1450.D Loss on real date 0.002\n",
      "Epoch 1450.G Loss 0.000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "\n",
    "d_minibatch_size = 15 \n",
    "g_minibatch_size = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    \"\"\"\n",
    "        训练Discriminator\n",
    "    \"\"\"\n",
    "    D.zero_grad()\n",
    "    # 用真实样本训练D \n",
    "    real_data = actual_data(d_minibatch_size, d_input_size)\n",
    "    real_decision = D(real_data)\n",
    "    real_error = -torch.sum(torch.log(real_decision))/d_minibatch_size\n",
    "    real_error.backward()\n",
    "    \n",
    "    # 用生成样本训练D\n",
    "    noise = noise_data(d_minibatch_size, g_input_size)\n",
    "    fake_data = G(noise) \n",
    "    fake_decision = D(fake_data)\n",
    "    fake_error = torch.sum(torch.log(fake_decision))/d_minibatch_size\n",
    "    fake_error.backward()\n",
    "    \n",
    "    d_optimizer.step()\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "        训练Generator\n",
    "    \"\"\"\n",
    "    G.zero_grad()\n",
    "    # 训练G\n",
    "    noise = noise_data(g_minibatch_size, g_input_size)\n",
    "    fake_data = G(noise)\n",
    "    fake_decision = D(fake_data)\n",
    "    gen_loss = -torch.sum(torch.log(fake_decision))/g_minibatch_size\n",
    "    gen_loss.backward()\n",
    "\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch %d.D Loss on real date %5.3f\" % (epoch, real_error))\n",
    "        print(\"Epoch %d.G Loss %5.3f\" % (epoch, gen_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
