{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来源：https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在两种流行的生成式模型：Generative Adversarial Nets (GAN)和Variational Autoencoder (VAE)。这两种模型有着本质上的不同，GAN基于博弈论，其目标是找到discriminator和generator间的纳什均衡；而VAE是基于贝叶斯推断，可以对数据的潜在分布建立概率分布模型，并从该分布中采集新样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE的公式与直观含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们想生成某种数据，可以假设该种数据由某种隐变量（latent variable）生成。在生成式模型中首先确定隐变量是很有用的，没有隐变量，那么数据只能盲目地生成。这是GAN和VAE的一大区别。VAE使用了隐变量，所以模型有时会花费较大的代价。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以定义如下记号："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$：我们想要生成的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z$：隐变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(X)$：数据$X$的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(z)$：隐变量$z$的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(X|z)$：在给定隐变量$z$时，$X$的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望对数据建模，因此希望直到$P(X)$，其可以表示成如下形式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(x)=\\int P(X|z)P(z)dz$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在VAE中，可以利用$P(z|X)$来估计$P(z)$。这有着直观的含义：我们希望让隐变量与真实数据相关，即用那些最可能生成真实数据的隐变量的分布$P(z|X)$来估计$P(z)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何估计$P(z|X)$？对分布的估计可以使用MCMC或者变分推断（Variational Inference，VI）。VI的核心思想利用一个简单分布（如高斯分布），不断逼近真实分布，即最小化两个分布间的KL散度。假设此处利用$Q(z|X)$来逼近$P(z|X)$，两者的KL散度表示如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D_{KL}[Q(z|X)\\parallel P(z|X)]=\\sum_{z}Q(z|X)\\log \\frac{Q(z|X)}{P(z|x)} = E_{z\\sim Q(z|X)}[\\frac{Q(z|X)}{P(z|X)}] = E_{z\\sim Q(z|X)}[\\log Q(z|X) -\\log P(z|X)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再由贝叶斯公式，上式可变成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E_{z\\sim Q(z|X)}[\\log Q(z|X) -\\log P(z|X)] = E_{z\\sim Q(z|X)}[\\log Q(z|X) -\\log \\frac{P(X|z)P(z)}{P(X)}] = E_{z\\sim Q(z|X)}[\\log Q(z|X) -\\log P(X|z)-\\log P(z)+\\log P(X)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于$P(X)$与$z$无关，所以可以将其移到等式左边，于是有："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D_{KL}[Q(z|X)\\parallel P(z|X)]-\\log P(X) = E_{z\\sim Q(z|X)}[\\log Q(z|X) -\\log P(X|z)-\\log P(z)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "左右同时乘-1，有：$\\log P(X) - D_{KL}[Q(z|X)\\parallel P(z|X)] = E_{z\\sim Q(z|X)}[\\log P(X|z) - (\\log Q(z|X)-\\log P(z))] = E_{z\\sim Q(z|X)}[\\log P(X|z) - D_{KL}[Q(z|X)\\parallel P(z)]]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\log P(X) - D_{KL}[Q(z|X)\\parallel P(z|X)]= E_{z\\sim Q(z|X)}[\\log P(X|z) - D_{KL}[Q(z|X)\\parallel P(z)]]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的就是VAE的目标函数。$P(X)$可以看成一个定值，因此我们希望等式左右两边的值越大越好。左边的$P(X|z)$是给定隐变量时真实数据的分布，可以看作解码器（decoder）；$Q(z|X)$是编码器（encoder），$z$是隐变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE的目标函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想要最大化$E_{z\\sim Q(z|X)}[\\log P(X|z) - D_{KL}[Q(z|X)\\parallel P(z)]]$，就要最大化$E_{z\\sim Q(z|X)}[P(X|z)]$，最小化$E_{z\\sim Q(z|X)}[D_{KL}[Q(z|X)\\parallel P(z)]]$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前个目标可以通过极大似然估计解决，将$z$看成输入，$X$看成输出，那么$P(X|z)$就是似然概率。通过极大似然估计就能得到该分布的参数的较好的估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  关于$D_{KL}[Q(z|X)\\parallel P(z)]$，这里$P(z)$是隐变量的分布，我们在生成样本时要对$z$进行采样，所以这里可以将$z$设为服从较易采样的高斯分布$N(0,1)$。于是现在的目标就变成了让$Q(z|X)$尽可能接近$N(0,1)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 假设我们希望$Q(z|X)$服从$N(\\mu(X),\\Sigma(X))$，此时KL散度有闭式解："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D_{KL}[N(\\mu(X),\\Sigma(X))\\parallel N(0,1)]=\\frac{1}{2}(tr(\\Sigma(X))+\\mu(X)^T \\mu(X)-k-\\log det(\\Sigma(X)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将$\\Sigma(X)$实现为一个向量，于是上式可以化简为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D_{KL}[N(\\mu(X),\\Sigma(X))\\parallel N(0,1)]=\\frac{1}{2}\\sum_{k}(\\Sigma(X)+\\mu(X)^2 -1-\\log \\Sigma(X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实践中，可将$\\log\\Sigma(X)$建模为$\\Sigma(X)$。因为计算指数比计算对数更数值稳定，于是有："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D_{KL}[N(\\mu(X),\\Sigma(X))\\parallel N(0,1)]=\\frac{1}{2}\\sum_{k}(\\exp(\\Sigma(X))+\\mu(X)^2 -1-\\Sigma(X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载mnist数据集\n",
    "\n",
    "# rgb通道：[0,255] => [0,1]\n",
    "mnist_trans = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "mnist_set = torchvision.datasets.MNIST('mnist', train=True, download=True, transform=mnist_trans)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 0, 2, 4, 1, 0, 4, 1, 2, 7, 7, 8, 8, 1, 5, 3, 5, 3, 5, 0, 1, 2, 0, 6,\n",
      "        9, 4, 7, 5, 3, 0, 6, 2, 4, 2, 6, 4, 2, 0, 7, 2, 0, 4, 9, 3, 7, 8, 7, 4,\n",
      "        4, 5, 4, 6, 7, 2, 1, 9, 6, 5, 9, 0, 4, 3, 2, 9, 1, 2, 9, 1, 6, 0, 7, 3,\n",
      "        7, 4, 9, 1, 1, 5, 6, 2, 4, 3, 4, 7, 0, 5, 3, 0, 8, 0, 2, 3, 5, 3, 3, 8,\n",
      "        0, 4, 4, 2, 0, 7, 4, 5, 9, 0, 8, 7, 5, 3, 4, 9, 0, 3, 3, 0, 3, 7, 9, 4,\n",
      "        3, 2, 7, 1, 5, 2, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "# 展示一张图片\n",
    "\n",
    "for data, label in train_loader:\n",
    "    fig = plt.figure()    \n",
    "    \n",
    "    print(data.shape)\n",
    "    plt.imshow(data[0][0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    print(label)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始构造VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encoder net Q(z|X)\n",
    "    其输入为真实数据X，输出为mu(X)和Sigma(X)。\n",
    "    \n",
    "    【先验】 我们令z服从高维高斯分布，其均值为0，协方差矩阵为I。即z~N(0,1)\n",
    "    【假设】 这里我们假设 z|X ~ N(mu(X), Sigma(X))，所以最后优化的一个目标就是\n",
    "             让这个分布与N(0,1)尽可能靠近（KL散度尽可能小）\n",
    "             \n",
    "    Q先从X中产生mu(X)和Sigma(X)，然后z再从中采样（采样在encoder net外）\n",
    "    \n",
    "  * Q相当于从数据X中“提取”出一个正态分布，将其视为z所服从的分布。在不断的优化中\n",
    "    使该分布逐步趋近标准正态分布\n",
    "    \n",
    "    \n",
    "    decoder net P(X|z)\n",
    "    输入隐变量，输出生成的数据X\n",
    "\"\"\"\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.z_dim = 100\n",
    "        \"\"\"\n",
    "            in encoder\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(784, 128)   # 784=28*28, size of input image\n",
    "        self.fc_z_mu = nn.Linear(128, self.z_dim)\n",
    "    \n",
    "        # 假设z的各维度相互独立，故Sigma(z)为对角矩阵，故可用向量表示\n",
    "        self.fc_z_sigma = nn.Linear(128, self.z_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "            in decoder\n",
    "        \"\"\"\n",
    "        self.fc2 = nn.Linear(self.z_dim, 128)\n",
    "        self.fc3 = nn.Linear(128, 784)\n",
    "        \n",
    "        \n",
    "    def encoder(self, X):\n",
    "        h1 = F.relu(self.fc1(X))\n",
    "        return self.fc_z_mu(h1), self.fc_z_sigma(h1)# 实践中，生成的实际上是log Sigma\n",
    "    \n",
    "    \n",
    "    # 由z|X ~ N(mu(X), Sigma(X))，对z进行采样\n",
    "    def sample_z(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar) # e^{(log var)/2} = var^{0.5}\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h1 = F.relu(self.fc2(z))\n",
    "        return torch.sigmoid(self.fc3(h1))\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        mu, logvar = self.encoder(X.view(-1, 784))\n",
    "        z = self.sample_z(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar   # 返回所有求loss时需要用到的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    下面是损失函数，分成两部分\n",
    "    1. BCE loss -> 使重建的数据和真实数据差别小(相当于前述的极大似然估计过程)\n",
    "    2. KLD loss -> 使隐变量的分布尽可能接近标准正态分布\n",
    "\"\"\"\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # recon_x是原本的x结果encoder net和decoder net后重建的结果\n",
    "    BCE_loss = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    \n",
    "    KLD_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return BCE_loss + KLD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 167.1508\n",
      "====> Epoch: 1 Average loss: 125.6100\n",
      "====> Epoch: 2 Average loss: 119.0786\n",
      "====> Epoch: 3 Average loss: 116.4446\n",
      "====> Epoch: 4 Average loss: 115.0512\n",
      "====> Epoch: 5 Average loss: 114.1624\n",
      "====> Epoch: 6 Average loss: 113.6753\n",
      "====> Epoch: 7 Average loss: 113.3248\n",
      "====> Epoch: 8 Average loss: 112.9817\n",
      "====> Epoch: 9 Average loss: 112.8498\n",
      "====> Epoch: 10 Average loss: 112.6293\n",
      "====> Epoch: 11 Average loss: 112.5093\n",
      "====> Epoch: 12 Average loss: 112.2959\n",
      "====> Epoch: 13 Average loss: 112.2171\n",
      "====> Epoch: 14 Average loss: 112.0854\n",
      "====> Epoch: 15 Average loss: 111.9911\n",
      "====> Epoch: 16 Average loss: 111.8361\n",
      "====> Epoch: 17 Average loss: 111.8010\n",
      "====> Epoch: 18 Average loss: 111.8427\n",
      "====> Epoch: 19 Average loss: 111.5658\n",
      "====> Epoch: 20 Average loss: 111.5766\n",
      "====> Epoch: 21 Average loss: 111.4930\n",
      "====> Epoch: 22 Average loss: 111.5032\n",
      "====> Epoch: 23 Average loss: 111.4384\n",
      "====> Epoch: 24 Average loss: 111.5431\n",
      "====> Epoch: 25 Average loss: 111.3111\n",
      "====> Epoch: 26 Average loss: 111.2997\n",
      "====> Epoch: 27 Average loss: 111.2878\n",
      "====> Epoch: 28 Average loss: 111.1998\n",
      "====> Epoch: 29 Average loss: 111.1756\n",
      "====> Epoch: 30 Average loss: 111.2128\n",
      "====> Epoch: 31 Average loss: 111.2031\n",
      "====> Epoch: 32 Average loss: 111.1681\n",
      "====> Epoch: 33 Average loss: 111.0286\n",
      "====> Epoch: 34 Average loss: 111.0263\n",
      "====> Epoch: 35 Average loss: 110.9926\n",
      "====> Epoch: 36 Average loss: 110.9868\n",
      "====> Epoch: 37 Average loss: 110.9388\n",
      "====> Epoch: 38 Average loss: 110.8196\n",
      "====> Epoch: 39 Average loss: 110.9674\n",
      "====> Epoch: 40 Average loss: 110.9134\n",
      "====> Epoch: 41 Average loss: 110.9372\n",
      "====> Epoch: 42 Average loss: 110.8010\n",
      "====> Epoch: 43 Average loss: 110.8528\n",
      "====> Epoch: 44 Average loss: 110.7310\n",
      "====> Epoch: 45 Average loss: 110.8016\n",
      "====> Epoch: 46 Average loss: 110.7981\n",
      "====> Epoch: 47 Average loss: 110.7104\n",
      "====> Epoch: 48 Average loss: 110.7309\n",
      "====> Epoch: 49 Average loss: 110.6778\n",
      "====> Epoch: 50 Average loss: 110.6810\n",
      "====> Epoch: 51 Average loss: 110.6697\n",
      "====> Epoch: 52 Average loss: 110.5741\n",
      "====> Epoch: 53 Average loss: 110.6510\n",
      "====> Epoch: 54 Average loss: 110.6090\n",
      "====> Epoch: 55 Average loss: 110.4859\n",
      "====> Epoch: 56 Average loss: 110.4662\n",
      "====> Epoch: 57 Average loss: 110.5539\n",
      "====> Epoch: 58 Average loss: 110.4780\n",
      "====> Epoch: 59 Average loss: 110.4413\n",
      "====> Epoch: 60 Average loss: 110.4153\n",
      "====> Epoch: 61 Average loss: 110.3778\n",
      "====> Epoch: 62 Average loss: 110.4059\n",
      "====> Epoch: 63 Average loss: 110.3825\n",
      "====> Epoch: 64 Average loss: 110.4894\n",
      "====> Epoch: 65 Average loss: 110.4144\n",
      "====> Epoch: 66 Average loss: 110.3799\n",
      "====> Epoch: 67 Average loss: 110.3676\n",
      "====> Epoch: 68 Average loss: 110.3776\n",
      "====> Epoch: 69 Average loss: 110.3744\n",
      "====> Epoch: 70 Average loss: 110.3802\n",
      "====> Epoch: 71 Average loss: 110.3924\n",
      "====> Epoch: 72 Average loss: 110.3508\n",
      "====> Epoch: 73 Average loss: 110.3443\n",
      "====> Epoch: 74 Average loss: 110.2713\n",
      "====> Epoch: 75 Average loss: 110.3571\n",
      "====> Epoch: 76 Average loss: 110.3601\n",
      "====> Epoch: 77 Average loss: 110.2674\n",
      "====> Epoch: 78 Average loss: 110.3103\n",
      "====> Epoch: 79 Average loss: 110.3266\n",
      "====> Epoch: 80 Average loss: 110.2636\n",
      "====> Epoch: 81 Average loss: 110.3103\n",
      "====> Epoch: 82 Average loss: 110.2252\n",
      "====> Epoch: 83 Average loss: 110.3212\n",
      "====> Epoch: 84 Average loss: 110.1896\n",
      "====> Epoch: 85 Average loss: 110.3226\n",
      "====> Epoch: 86 Average loss: 110.3513\n",
      "====> Epoch: 87 Average loss: 110.2914\n",
      "====> Epoch: 88 Average loss: 110.1868\n",
      "====> Epoch: 89 Average loss: 110.3233\n",
      "====> Epoch: 90 Average loss: 110.1892\n",
      "====> Epoch: 91 Average loss: 110.2303\n",
      "====> Epoch: 92 Average loss: 110.2993\n",
      "====> Epoch: 93 Average loss: 110.2905\n",
      "====> Epoch: 94 Average loss: 110.1901\n",
      "====> Epoch: 95 Average loss: 110.1801\n",
      "====> Epoch: 96 Average loss: 110.1952\n",
      "====> Epoch: 97 Average loss: 110.2650\n",
      "====> Epoch: 98 Average loss: 110.2010\n",
      "====> Epoch: 99 Average loss: 110.2195\n",
      "====> Epoch: 100 Average loss: 110.1735\n",
      "====> Epoch: 101 Average loss: 110.2557\n",
      "====> Epoch: 102 Average loss: 110.1182\n",
      "====> Epoch: 103 Average loss: 110.1361\n",
      "====> Epoch: 104 Average loss: 110.2527\n",
      "====> Epoch: 105 Average loss: 110.1675\n",
      "====> Epoch: 106 Average loss: 110.1717\n",
      "====> Epoch: 107 Average loss: 110.1729\n",
      "====> Epoch: 108 Average loss: 110.0780\n",
      "====> Epoch: 109 Average loss: 110.2009\n",
      "====> Epoch: 110 Average loss: 110.1970\n",
      "====> Epoch: 111 Average loss: 110.1059\n",
      "====> Epoch: 112 Average loss: 110.1726\n",
      "====> Epoch: 113 Average loss: 110.2387\n",
      "====> Epoch: 114 Average loss: 110.1617\n",
      "====> Epoch: 115 Average loss: 110.1270\n",
      "====> Epoch: 116 Average loss: 110.1178\n",
      "====> Epoch: 117 Average loss: 110.1940\n",
      "====> Epoch: 118 Average loss: 110.1763\n",
      "====> Epoch: 119 Average loss: 110.0987\n",
      "====> Epoch: 120 Average loss: 110.1545\n",
      "====> Epoch: 121 Average loss: 110.1652\n",
      "====> Epoch: 122 Average loss: 110.1289\n",
      "====> Epoch: 123 Average loss: 110.1255\n",
      "====> Epoch: 124 Average loss: 110.1265\n",
      "====> Epoch: 125 Average loss: 110.1819\n",
      "====> Epoch: 126 Average loss: 110.0564\n",
      "====> Epoch: 127 Average loss: 110.1015\n",
      "====> Epoch: 128 Average loss: 110.1043\n",
      "====> Epoch: 129 Average loss: 110.1161\n",
      "====> Epoch: 130 Average loss: 110.1497\n",
      "====> Epoch: 131 Average loss: 110.0770\n",
      "====> Epoch: 132 Average loss: 110.0640\n",
      "====> Epoch: 133 Average loss: 110.1324\n",
      "====> Epoch: 134 Average loss: 110.1629\n",
      "====> Epoch: 135 Average loss: 110.1291\n",
      "====> Epoch: 136 Average loss: 110.1175\n",
      "====> Epoch: 137 Average loss: 110.0637\n",
      "====> Epoch: 138 Average loss: 110.0896\n",
      "====> Epoch: 139 Average loss: 110.0816\n",
      "====> Epoch: 140 Average loss: 110.1384\n",
      "====> Epoch: 141 Average loss: 110.0576\n",
      "====> Epoch: 142 Average loss: 110.1139\n",
      "====> Epoch: 143 Average loss: 110.1470\n",
      "====> Epoch: 144 Average loss: 110.1293\n",
      "====> Epoch: 145 Average loss: 110.0844\n",
      "====> Epoch: 146 Average loss: 110.1305\n",
      "====> Epoch: 147 Average loss: 110.1645\n",
      "====> Epoch: 148 Average loss: 110.2112\n",
      "====> Epoch: 149 Average loss: 110.0462\n",
      "====> Epoch: 150 Average loss: 110.1001\n",
      "====> Epoch: 151 Average loss: 110.1131\n",
      "====> Epoch: 152 Average loss: 110.0353\n",
      "====> Epoch: 153 Average loss: 110.0650\n",
      "====> Epoch: 154 Average loss: 110.0798\n",
      "====> Epoch: 155 Average loss: 110.0478\n",
      "====> Epoch: 156 Average loss: 110.0139\n",
      "====> Epoch: 157 Average loss: 110.1529\n",
      "====> Epoch: 158 Average loss: 110.0347\n",
      "====> Epoch: 159 Average loss: 110.1338\n",
      "====> Epoch: 160 Average loss: 110.0467\n",
      "====> Epoch: 161 Average loss: 110.1090\n",
      "====> Epoch: 162 Average loss: 110.0373\n",
      "====> Epoch: 163 Average loss: 110.0989\n",
      "====> Epoch: 164 Average loss: 110.1402\n",
      "====> Epoch: 165 Average loss: 110.1713\n",
      "====> Epoch: 166 Average loss: 110.0528\n",
      "====> Epoch: 167 Average loss: 110.0385\n",
      "====> Epoch: 168 Average loss: 110.0822\n",
      "====> Epoch: 169 Average loss: 110.0928\n",
      "====> Epoch: 170 Average loss: 110.0346\n",
      "====> Epoch: 171 Average loss: 110.1045\n",
      "====> Epoch: 172 Average loss: 110.1174\n",
      "====> Epoch: 173 Average loss: 110.0881\n",
      "====> Epoch: 174 Average loss: 110.0566\n",
      "====> Epoch: 175 Average loss: 110.1062\n",
      "====> Epoch: 176 Average loss: 110.0212\n",
      "====> Epoch: 177 Average loss: 110.1121\n",
      "====> Epoch: 178 Average loss: 109.9762\n",
      "====> Epoch: 179 Average loss: 110.0912\n",
      "====> Epoch: 180 Average loss: 110.0827\n",
      "====> Epoch: 181 Average loss: 110.0662\n",
      "====> Epoch: 182 Average loss: 110.1318\n",
      "====> Epoch: 183 Average loss: 110.0237\n",
      "====> Epoch: 184 Average loss: 110.0202\n",
      "====> Epoch: 185 Average loss: 110.0253\n",
      "====> Epoch: 186 Average loss: 110.1566\n",
      "====> Epoch: 187 Average loss: 110.0333\n",
      "====> Epoch: 188 Average loss: 110.0283\n",
      "====> Epoch: 189 Average loss: 110.0247\n",
      "====> Epoch: 190 Average loss: 110.0643\n",
      "====> Epoch: 191 Average loss: 110.0485\n",
      "====> Epoch: 192 Average loss: 109.9800\n",
      "====> Epoch: 193 Average loss: 110.0156\n",
      "====> Epoch: 194 Average loss: 110.0206\n",
      "====> Epoch: 195 Average loss: 110.0976\n",
      "====> Epoch: 196 Average loss: 110.0205\n",
      "====> Epoch: 197 Average loss: 110.0258\n",
      "====> Epoch: 198 Average loss: 110.0409\n",
      "====> Epoch: 199 Average loss: 110.1017\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面利用训练好的decoder net生成若干图片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(100).to(device)\n",
    "\n",
    "output = model.decoder(z).view(28,28).detach()\n",
    "\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'my_vae.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
